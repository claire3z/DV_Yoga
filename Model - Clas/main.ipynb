{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%run nets.ipynb\n",
    "%run plot_graphs.ipynb\n",
    "import shutil\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    data = torch.load(path + '/data_train_train.pt').float()\n",
    "    labels_ = torch.load(path + '/labels_train_train.pt').long()\n",
    "    dataTest = torch.load(path + '/data_train_eval.pt').float()\n",
    "    labelsTest = torch.load(path + '/labels_train_eval.pt').long()\n",
    "    poseTrain = torch.load(path + '/data_train_train_key.pt').float()\n",
    "    poseTest = torch.load(path + '/data_train_eval_key.pt').float()\n",
    "    poseTrain1 = torch.load(path + '/data_train_train_key_1.pt').float()\n",
    "    poseTest1 = torch.load(path + '/data_train_eval_key_1.pt').float()\n",
    "    return data, labels_, dataTest, labelsTest, poseTrain, poseTest, poseTrain1, poseTest1\n",
    "\n",
    "\n",
    "\n",
    "def train(modelName, learning_rate, weightedHier = None, num_epochs = 3, batch_size = 2, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = False, ckp_path = None):\n",
    "\n",
    "    \n",
    "    #init\n",
    "    name = modelName + \"_\" + str(learning_rate) + \"_\" + str(dropout) + str(num_epochs) \n",
    "    checkpoint_path = \"./checkpoints/\" + name\n",
    "    best_model_path = \"./bestModels/\" + name\n",
    "    try:\n",
    "        makedirs('./checkpoints')\n",
    "    except Exception as e:\n",
    "        None\n",
    "    try:\n",
    "        makedirs('./bestModels')\n",
    "    except Exception as e:\n",
    "        None\n",
    "    bestAcc = 0.0\n",
    "    \n",
    "    \n",
    "    #reproducibility\n",
    "    if reproducibility == True:\n",
    "        torch.manual_seed(30)\n",
    "        torch.cuda.manual_seed(30)\n",
    "        np.random.seed(30)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # initialize network\n",
    "    print(modelName)\n",
    "    if modelName == \"cnn\":\n",
    "        model = myModel(\"cnn\",dropout = 0.2)\n",
    "    elif modelName == \"hier\":\n",
    "        model = myModel(\"hier\",dropout = 0.2)\n",
    "    elif modelName == \"combined1\":\n",
    "        model = myModel(\"combined1\",dropout = 0.2)\n",
    "    elif modelName == \"combined2\":\n",
    "        model = myModel(\"combined2\",dropout = 0.2)\n",
    "    elif modelName == \"pose\":\n",
    "        model = Net_pose()\n",
    "    elif modelName == \"dense\":\n",
    "        modelName = \"cnn\"\n",
    "        model = DenseNet3(82, \"cnn\", growth_rate=6,\n",
    "                 reduction=0.5, bottleneck=True, dropRate=0.2)\n",
    "    elif modelName == \"dense_hier\":\n",
    "        modelName = \"hier\"\n",
    "        model = DenseNet3(82, \"hier\", growth_rate=6,\n",
    "                 reduction=0.5, bottleneck=True, dropRate=0.2)\n",
    "    elif modelName == \"dense_combined1\":\n",
    "        modelName = \"combined1\"\n",
    "        model = DenseNet3(82, \"combined1\", growth_rate=6,\n",
    "                 reduction=0.5, bottleneck=True, dropRate=0.2)\n",
    "    elif modelName == \"dense_combined2\":\n",
    "        modelName = \"combined2\"\n",
    "        model = DenseNet3(82, \"combined2\", growth_rate=6,\n",
    "                 reduction=0.5, bottleneck=True, dropRate=0.2)\n",
    "    else:\n",
    "        print(\"model name does not exist\")\n",
    "        return 0\n",
    "    model.to(device)\n",
    "    \n",
    "    \n",
    "    #set hyperparameter\n",
    "    if weightedHier == None:\n",
    "        weightedHier = [1/3,1/3,1/3]\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum = 0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True, threshold=0.001, factor=0.5)\n",
    "\n",
    "    # prepare train\n",
    "    accList1 = []\n",
    "    accList2 = []\n",
    "    accList3 = []\n",
    "    start_epoch = 0\n",
    "    #mesures true positive,false positive and false negative (checkpoint not working for metrics right now)\n",
    "    metrics = np.zeros((num_epochs,82,3)) \n",
    "    \n",
    "    num_Batches = int(data.shape[0] / batch_size)\n",
    "    if data.shape[0] % batch_size != 0:\n",
    "        num_Batches += 1\n",
    "\n",
    "    #load model from checkpoint and continue training\n",
    "    if ckp_path != None:\n",
    "        model, optimizer, scheduler, start_epoch, bestAcc, accList1, accList2, accList3 = load_ckp(ckp_path, model, optimizer, scheduler)\n",
    "        num_epochs -= start_epoch\n",
    "        \n",
    "        \n",
    "    #train\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i in range(num_Batches):\n",
    "            #get the correct slice of the data\n",
    "            cutBatch = (i+1)*batch_size\n",
    "            if i == num_Batches - 1:\n",
    "                cutBatch = None\n",
    "            \n",
    "            #get the correct data for the model type\n",
    "            labels = labels_[i*batch_size:cutBatch]\n",
    "            if modelName != \"pose\":\n",
    "                images = data[i*batch_size:cutBatch] \n",
    "            if modelName == \"combined1\" or modelName == \"pose\": \n",
    "                keys = poseTrain[i*batch_size:cutBatch] \n",
    "            elif modelName == \"combined2\":\n",
    "                keys = poseTrain1[i*batch_size:cutBatch]\n",
    "            \n",
    "            if modelName == \"combined1\" or modelName == \"pose\":\n",
    "                keys = Variable(keys.view(keys.shape[0],51))\n",
    "            if modelName != \"pose\":\n",
    "                train = Variable(images.view(images.shape[0],100,100,3))\n",
    "                train = torch.transpose(train, 1, 3)\n",
    "                train = torch.transpose(train, 2, 3)\n",
    "            if modelName == \"combined2\":\n",
    "                keys = Variable(keys.view(keys.shape[0],1,100,100))\n",
    "                train = torch.cat((train, keys), dim=1)\n",
    "            labels1 = Variable(labels[:,0])\n",
    "            labels2 = Variable(labels[:,1])\n",
    "            labels3 = Variable(labels[:,2])\n",
    "            \n",
    "            if modelName != \"pose\":\n",
    "                train = train.to(device).to(torch.float)\n",
    "            if modelName != \"cnn\" and modelName != \"hier\":\n",
    "                keys = keys.to(device).to(torch.float)\n",
    "            labels1, labels2, labels3 = (\n",
    "                labels1.to(device),\n",
    "                labels2.to(device),\n",
    "                labels3.to(device),\n",
    "            )\n",
    "            \n",
    "            #run data trough model\n",
    "            optimizer.zero_grad()\n",
    "            if modelName == \"cnn\":\n",
    "                outputs = model(train)\n",
    "                loss = error(outputs, labels3)\n",
    "            elif modelName == \"pose\":\n",
    "                outputs = model(keys)\n",
    "                loss = error(outputs, labels3)\n",
    "            else:\n",
    "                if modelName == \"combined1\":\n",
    "                    a,b,outputs = model(train,keys)\n",
    "                else:\n",
    "                    a,b,outputs = model(train)\n",
    "                loss1 = error(a, labels1)\n",
    "                loss2 = error(b, labels2)\n",
    "                loss3 = error(outputs, labels3)\n",
    "                loss = weightedHier[0]*loss1 + weightedHier[1]*loss2 + weightedHier[2]*loss3\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        # eval\n",
    "        with torch.no_grad():\n",
    "            #prepare eval\n",
    "            model.eval()\n",
    "            correct1 = 0\n",
    "            total = 0\n",
    "            correct2 = 0\n",
    "            correct3 = 0\n",
    "            totalLoss = 0\n",
    "            \n",
    "            #get the correct slice of the data type\n",
    "            num_Batches_test = int(dataTest.shape[0] / batch_size)\n",
    "            if dataTest.shape[0] % batch_size != 0:\n",
    "                num_Batches_test += 1\n",
    "            for i in range(num_Batches_test):\n",
    "                cutBatch = (i+1)*batch_size\n",
    "                if i == num_Batches - 1:\n",
    "                    cutBatch = None\n",
    "                    \n",
    "                #get the correct data for model\n",
    "                labels = labelsTest[i*batch_size:cutBatch]\n",
    "                if modelName != \"pose\":\n",
    "                    images = dataTest[i*batch_size:cutBatch]\n",
    "                if modelName == \"combined1\" or modelName == \"pose\": \n",
    "                    keysLabel = poseTest[i*batch_size:cutBatch] \n",
    "                elif modelName == \"combined2\":\n",
    "                    keysLabel = poseTest1[i*batch_size:cutBatch]\n",
    "\n",
    "                if modelName == \"combined1\" or modelName == \"pose\":\n",
    "                    keysLabel = Variable(keysLabel.view(keysLabel.shape[0],51))\n",
    "                if modelName != \"pose\":\n",
    "                    test = Variable(images.view(images.shape[0],100,100,3))\n",
    "                    test = torch.transpose(test, 1, 3)\n",
    "                    test = torch.transpose(test, 2, 3)\n",
    "                if modelName == \"combined2\":\n",
    "                    keysLabel = Variable(keysLabel.view(keysLabel.shape[0],1,100,100))\n",
    "                    test = torch.cat((test, keysLabel), dim=1)\n",
    "                labels1 = Variable(labels[:,0])\n",
    "                labels2 = Variable(labels[:,1])\n",
    "                labels3 = Variable(labels[:,2])\n",
    "\n",
    "                if modelName != \"pose\":\n",
    "                    test = test.to(device).to(torch.float)\n",
    "                if modelName != \"cnn\" and modelName != \"hier\":\n",
    "                    keysLabel = keysLabel.to(device).to(torch.float)\n",
    "                labels1, labels2, labels3 = (\n",
    "                    labels1.to(device),\n",
    "                    labels2.to(device),\n",
    "                    labels3.to(device),\n",
    "                )\n",
    "\n",
    "                #compute accuracies, loss and metrices\n",
    "                if modelName == \"cnn\":\n",
    "                    outputs = model(test)\n",
    "                    loss = error(outputs, labels3)\n",
    "                elif modelName == \"pose\":\n",
    "                    outputs = model(keysLabel)\n",
    "                    loss = error(outputs, labels3)\n",
    "                else:\n",
    "                    if modelName == \"combined1\":\n",
    "                        a,b,outputs = model(test,keysLabel)\n",
    "                    else:\n",
    "                        a,b,outputs = model(test)\n",
    "                    predicted1 = torch.max(a.data, 1)[1]\n",
    "                    predicted2 = torch.max(b.data, 1)[1]\n",
    "                    correct1 += (predicted1 == labels1).sum()\n",
    "                    correct2 += (predicted2 == labels2).sum()\n",
    "                    loss1 = error(a, labels1)\n",
    "                    loss2 = error(b, labels2)\n",
    "                    loss3 = error(outputs, labels3)\n",
    "                    loss = weightedHier[0]*loss1 + weightedHier[1]*loss2 + weightedHier[2]*loss3\n",
    "                predicted3 = torch.max(outputs.data, 1)[1]  \n",
    "                total += len(labels3)\n",
    "                correct3 += (predicted3 == labels3).sum()\n",
    "                totalLoss += loss.sum()\n",
    "\n",
    "                for pred,lab in zip(predicted3,labels3):\n",
    "                    if pred == lab:\n",
    "                        metrics[epoch][pred][0] += 1\n",
    "                    else:\n",
    "                        metrics[epoch][pred][1] += 1\n",
    "                        metrics[epoch][lab][2] += 1\n",
    "            if modelName != \"cnn\" and modelName != \"pose\":\n",
    "                accuracy1 = 100 * correct1 / float(total)\n",
    "                accuracy2 = 100 * correct2 / float(total)\n",
    "            accuracy3 = 100 * correct3 / float(total)\n",
    "            epochLoss = totalLoss / float(total)\n",
    "            \n",
    "            scheduler.step(epochLoss)\n",
    "            \n",
    "            #print progress\n",
    "            if modelName != \"cnn\" and modelName != \"pose\":\n",
    "                print('Epoch: {}  accuracy1: {}  accuracy2: {}  accuracy3: {}  overall loss: {}'.format(epoch+1+start_epoch, \n",
    "                                                                            accuracy1,accuracy2,accuracy3,epochLoss))\n",
    "                accList1.append(accuracy1.item())\n",
    "                accList2.append(accuracy2.item())\n",
    "            else:\n",
    "                print('Epoch: {}  accuracy: {}  loss: {}'.format(epoch+1+start_epoch, accuracy3,epochLoss))\n",
    "            accList3.append(accuracy3.item())\n",
    "\n",
    "\n",
    "        # save best model\n",
    "        if accuracy3 >= bestAcc:\n",
    "            # save as best model\n",
    "            torch.save(model, \"./bestModels/\" + name)\n",
    "            bestAcc = accuracy3\n",
    "\n",
    "            \n",
    "        # create checkpoint variable and add important data\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'bestAcc': bestAcc,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'accList1': accList1,\n",
    "            'accList2': accList2,\n",
    "            'accList3': accList3,\n",
    "        }\n",
    "        # save checkpoint\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "            \n",
    "            \n",
    "            \n",
    "    #plot the accuracies\n",
    "    if buildGraphs == True: \n",
    "        try:\n",
    "            makedirs('./plots')\n",
    "        except Exception as e:\n",
    "            None\n",
    "        if ckp_path == None:\n",
    "            metrics = metrics.reshape(num_epochs,82*3)\n",
    "            np.savetxt(\"./plots/\" + name + \"_metrics_.txt\", metrics, fmt='%d')\n",
    "        if modelName != \"CNN\" and modelName != \"pose\":\n",
    "            plot_history([accList1, accList2, accList3], name)\n",
    "        else:\n",
    "            plot_history([accList3], name)\n",
    "        with open(\"./plots/\" + name + \"_acc.txt\", \"wb\") as fp:   #Pickling\n",
    "            pickle.dump([accList1, accList2, accList3], fp)\n",
    "        \n",
    "    #save final model\n",
    "    try:\n",
    "        makedirs('./models')\n",
    "    except Exception as e:\n",
    "        None\n",
    "    torch.save(model, \"./models/\" + name)\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_ckp(checkpoint_path, model, optimizer, scheduler):\n",
    "    \"\"\"\n",
    "    checkpoint_path: path to save checkpoint\n",
    "    model: model to load checkpoint parameters into       \n",
    "    optimizer: optimizer to use\n",
    "    scheduler: scheduler to use\n",
    "    \"\"\"\n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    # initialize\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    bestAcc = checkpoint['bestAcc']\n",
    "    return model, optimizer, scheduler, checkpoint['epoch'], bestAcc, checkpoint['accList1'],checkpoint['accList2'], checkpoint['accList3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load entire data\n",
    "data, labels_, dataTest, labelsTest, poseTrain, poseTest, poseTrain1, poseTest1 = loadData(\"./allData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "dense_combined1\n",
      "Epoch: 1  accuracy1: 32.62883758544922  accuracy2: 12.275622367858887  accuracy3: 12.217719078063965  overall loss: 0.18553267419338226\n",
      "Epoch: 2  accuracy1: 37.17428970336914  accuracy2: 20.208454132080078  accuracy3: 13.144181251525879  overall loss: 0.1653822660446167\n",
      "Epoch: 3  accuracy1: 42.55935287475586  accuracy2: 25.07238006591797  accuracy3: 16.41575050354004  overall loss: 0.1561366766691208\n",
      "Epoch: 4  accuracy1: 43.94904708862305  accuracy2: 29.183555603027344  accuracy3: 18.09496307373047  overall loss: 0.15156812965869904\n",
      "Epoch: 5  accuracy1: 43.42790985107422  accuracy2: 28.517662048339844  accuracy3: 19.80312728881836  overall loss: 0.15192696452140808\n",
      "Epoch: 6  accuracy1: 44.296470642089844  accuracy2: 29.878402709960938  accuracy3: 21.453388214111328  overall loss: 0.1494004875421524\n",
      "Epoch: 7  accuracy1: 46.467864990234375  accuracy2: 32.513031005859375  accuracy3: 22.5825138092041  overall loss: 0.14601850509643555\n",
      "Epoch: 8  accuracy1: 47.307472229003906  accuracy2: 33.005210876464844  accuracy3: 22.95888900756836  overall loss: 0.14656709134578705\n",
      "Epoch: 9  accuracy1: 47.48118209838867  accuracy2: 33.67110824584961  accuracy3: 23.82744789123535  overall loss: 0.14654941856861115\n",
      "Epoch: 10  accuracy1: 47.27851867675781  accuracy2: 35.17660903930664  accuracy3: 24.088014602661133  overall loss: 0.14829705655574799\n",
      "Epoch    11: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 11  accuracy1: 48.378692626953125  accuracy2: 36.3925895690918  accuracy3: 23.653736114501953  overall loss: 0.14756004512310028\n",
      "Epoch: 12  accuracy1: 47.74174880981445  accuracy2: 37.34800338745117  accuracy3: 27.243776321411133  overall loss: 0.14457863569259644\n",
      "Epoch: 13  accuracy1: 48.581356048583984  accuracy2: 37.463809967041016  accuracy3: 27.64910316467285  overall loss: 0.14516901969909668\n",
      "Epoch: 14  accuracy1: 48.23393249511719  accuracy2: 37.43486022949219  accuracy3: 27.967575073242188  overall loss: 0.1460205465555191\n",
      "Epoch: 15  accuracy1: 48.668212890625  accuracy2: 37.666473388671875  accuracy3: 27.764911651611328  overall loss: 0.1472424864768982\n",
      "Epoch    16: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 16  accuracy1: 47.85755920410156  accuracy2: 37.782283782958984  accuracy3: 28.199190139770508  overall loss: 0.14830178022384644\n",
      "Epoch: 17  accuracy1: 48.89982604980469  accuracy2: 39.02721405029297  accuracy3: 29.29936408996582  overall loss: 0.1458144336938858\n",
      "Epoch: 18  accuracy1: 48.841922760009766  accuracy2: 39.05616760253906  accuracy3: 29.415170669555664  overall loss: 0.14651119709014893\n",
      "Epoch: 19  accuracy1: 48.957733154296875  accuracy2: 39.5193977355957  accuracy3: 29.50202751159668  overall loss: 0.14736853539943695\n",
      "Epoch    20: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 20  accuracy1: 48.3207893371582  accuracy2: 39.114070892333984  accuracy3: 29.47307586669922  overall loss: 0.14824572205543518\n",
      "Epoch: 21  accuracy1: 49.218299865722656  accuracy2: 39.22987747192383  accuracy3: 30.023162841796875  overall loss: 0.14722391963005066\n",
      "Epoch: 22  accuracy1: 49.363059997558594  accuracy2: 39.490447998046875  accuracy3: 30.081066131591797  overall loss: 0.14770348370075226\n",
      "Epoch: 23  accuracy1: 49.07353973388672  accuracy2: 39.374637603759766  accuracy3: 30.254777908325195  overall loss: 0.14764104783535004\n",
      "Epoch    24: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 24  accuracy1: 49.623626708984375  accuracy2: 39.5193977355957  accuracy3: 30.457441329956055  overall loss: 0.14819513261318207\n",
      "Epoch: 25  accuracy1: 49.47886657714844  accuracy2: 39.577301025390625  accuracy3: 31.00752830505371  overall loss: 0.1473124772310257\n",
      "Epoch: 26  accuracy1: 49.247249603271484  accuracy2: 39.751014709472656  accuracy3: 31.354951858520508  overall loss: 0.1473669409751892\n",
      "Epoch: 27  accuracy1: 49.247249603271484  accuracy2: 39.895774841308594  accuracy3: 31.41285514831543  overall loss: 0.14761197566986084\n",
      "Epoch    28: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 28  accuracy1: 49.420963287353516  accuracy2: 39.72206115722656  accuracy3: 31.557615280151367  overall loss: 0.14765122532844543\n",
      "Epoch: 29  accuracy1: 49.27620315551758  accuracy2: 39.751014709472656  accuracy3: 31.673423767089844  overall loss: 0.14759747684001923\n",
      "Epoch: 30  accuracy1: 49.39200973510742  accuracy2: 39.8668212890625  accuracy3: 31.789230346679688  overall loss: 0.14767734706401825\n",
      "Epoch: 31  accuracy1: 49.39200973510742  accuracy2: 39.8668212890625  accuracy3: 31.789230346679688  overall loss: 0.14775727689266205\n",
      "Epoch    32: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 32  accuracy1: 49.218299865722656  accuracy2: 40.156341552734375  accuracy3: 31.933990478515625  overall loss: 0.14788039028644562\n",
      "Epoch: 33  accuracy1: 49.449913024902344  accuracy2: 40.12738800048828  accuracy3: 32.02084732055664  overall loss: 0.1477513313293457\n",
      "Epoch: 34  accuracy1: 49.18934631347656  accuracy2: 40.04053497314453  accuracy3: 31.991893768310547  overall loss: 0.14775781333446503\n",
      "Epoch: 35  accuracy1: 49.305152893066406  accuracy2: 40.04053497314453  accuracy3: 31.991893768310547  overall loss: 0.1478072702884674\n",
      "Epoch    36: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 36  accuracy1: 49.363059997558594  accuracy2: 39.83787155151367  accuracy3: 32.04979705810547  overall loss: 0.14793363213539124\n",
      "Epoch: 37  accuracy1: 49.247249603271484  accuracy2: 39.8668212890625  accuracy3: 32.136653900146484  overall loss: 0.1478242129087448\n",
      "Epoch: 38  accuracy1: 49.305152893066406  accuracy2: 39.98263168334961  accuracy3: 32.10770034790039  overall loss: 0.14788860082626343\n",
      "Epoch: 39  accuracy1: 49.247249603271484  accuracy2: 39.92472457885742  accuracy3: 32.07875061035156  overall loss: 0.1479286253452301\n",
      "Epoch    40: reducing learning rate of group 0 to 1.1719e-05.\n",
      "Epoch: 40  accuracy1: 49.218299865722656  accuracy2: 39.895774841308594  accuracy3: 32.02084732055664  overall loss: 0.14793935418128967\n",
      "saved modelsGraph.png\n",
      "Using device: cuda:0\n",
      "dense_combined2\n",
      "Epoch: 1  accuracy1: 37.0584831237793  accuracy2: 15.026057243347168  accuracy3: 3.8795599937438965  overall loss: 0.18530823290348053\n",
      "Epoch: 2  accuracy1: 39.80891799926758  accuracy2: 22.35089874267578  accuracy3: 4.111175537109375  overall loss: 0.1765710711479187\n",
      "Epoch: 3  accuracy1: 43.051536560058594  accuracy2: 25.622467041015625  accuracy3: 4.400694847106934  overall loss: 0.17457164824008942\n",
      "Epoch: 4  accuracy1: 45.888824462890625  accuracy2: 31.557615280151367  accuracy3: 3.9664158821105957  overall loss: 0.16873522102832794\n",
      "Epoch: 5  accuracy1: 43.514766693115234  accuracy2: 31.268095016479492  accuracy3: 4.169079303741455  overall loss: 0.17105011641979218\n",
      "Epoch: 6  accuracy1: 46.467864990234375  accuracy2: 34.047481536865234  accuracy3: 4.255935192108154  overall loss: 0.16717849671840668\n",
      "Epoch: 7  accuracy1: 46.14939498901367  accuracy2: 33.70005798339844  accuracy3: 4.719166278839111  overall loss: 0.16898804903030396\n",
      "Epoch: 8  accuracy1: 47.539085388183594  accuracy2: 35.495079040527344  accuracy3: 4.255935192108154  overall loss: 0.16754189133644104\n",
      "Epoch: 9  accuracy1: 47.48118209838867  accuracy2: 36.30573272705078  accuracy3: 4.458598613739014  overall loss: 0.1682371199131012\n",
      "Epoch    10: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 10  accuracy1: 47.539085388183594  accuracy2: 36.334686279296875  accuracy3: 4.516502857208252  overall loss: 0.16928048431873322\n",
      "Epoch: 11  accuracy1: 49.305152893066406  accuracy2: 37.7243766784668  accuracy3: 4.83497428894043  overall loss: 0.16955113410949707\n",
      "Epoch: 12  accuracy1: 48.61030960083008  accuracy2: 38.10075378417969  accuracy3: 4.8060221672058105  overall loss: 0.17039914429187775\n",
      "Epoch: 13  accuracy1: 48.784019470214844  accuracy2: 38.10075378417969  accuracy3: 4.7481184005737305  overall loss: 0.17077231407165527\n",
      "Epoch    14: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 14  accuracy1: 48.14707565307617  accuracy2: 38.41922378540039  accuracy3: 4.863925933837891  overall loss: 0.1731654554605484\n",
      "Epoch: 15  accuracy1: 49.826290130615234  accuracy2: 39.34568786621094  accuracy3: 4.921829700469971  overall loss: 0.17090542614459991\n",
      "Epoch: 16  accuracy1: 49.56572341918945  accuracy2: 39.8668212890625  accuracy3: 4.89287805557251  overall loss: 0.17131590843200684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17  accuracy1: 50.289520263671875  accuracy2: 39.577301025390625  accuracy3: 4.89287805557251  overall loss: 0.17207182943820953\n",
      "Epoch    18: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 18  accuracy1: 50.028953552246094  accuracy2: 39.490447998046875  accuracy3: 4.95078182220459  overall loss: 0.1723647564649582\n",
      "Epoch: 19  accuracy1: 49.79733657836914  accuracy2: 39.953678131103516  accuracy3: 4.95078182220459  overall loss: 0.1717727780342102\n",
      "Epoch: 20  accuracy1: 50.43428039550781  accuracy2: 39.490447998046875  accuracy3: 4.89287805557251  overall loss: 0.17219285666942596\n",
      "Epoch: 21  accuracy1: 50.463233947753906  accuracy2: 39.751014709472656  accuracy3: 5.06658935546875  overall loss: 0.17268545925617218\n",
      "Epoch    22: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 22  accuracy1: 50.289520263671875  accuracy2: 39.8668212890625  accuracy3: 5.037637710571289  overall loss: 0.1730097234249115\n",
      "Epoch: 23  accuracy1: 50.43428039550781  accuracy2: 39.98263168334961  accuracy3: 5.095541477203369  overall loss: 0.17275506258010864\n",
      "Epoch: 24  accuracy1: 50.23161697387695  accuracy2: 39.779964447021484  accuracy3: 5.06658935546875  overall loss: 0.17338970303535461\n",
      "Epoch: 25  accuracy1: 50.52113723754883  accuracy2: 40.156341552734375  accuracy3: 5.037637710571289  overall loss: 0.17329959571361542\n",
      "Epoch    26: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 26  accuracy1: 50.60799026489258  accuracy2: 40.09843826293945  accuracy3: 5.153445243835449  overall loss: 0.17348216474056244\n",
      "Epoch: 27  accuracy1: 50.52113723754883  accuracy2: 39.895774841308594  accuracy3: 5.2113494873046875  overall loss: 0.1733696609735489\n",
      "Epoch: 28  accuracy1: 50.463233947753906  accuracy2: 40.18529510498047  accuracy3: 5.182397365570068  overall loss: 0.17328794300556183\n",
      "Epoch: 29  accuracy1: 50.17371368408203  accuracy2: 40.12738800048828  accuracy3: 5.182397365570068  overall loss: 0.17354653775691986\n",
      "Epoch    30: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 30  accuracy1: 50.492183685302734  accuracy2: 40.156341552734375  accuracy3: 5.06658935546875  overall loss: 0.17350761592388153\n",
      "Epoch: 31  accuracy1: 50.43428039550781  accuracy2: 40.12738800048828  accuracy3: 5.2113494873046875  overall loss: 0.17346984148025513\n",
      "Epoch: 32  accuracy1: 50.40532684326172  accuracy2: 40.06948471069336  accuracy3: 5.240301132202148  overall loss: 0.17359359562397003\n",
      "Epoch: 33  accuracy1: 50.40532684326172  accuracy2: 40.01158142089844  accuracy3: 5.269253253936768  overall loss: 0.1736098825931549\n",
      "Epoch    34: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 34  accuracy1: 50.31847381591797  accuracy2: 40.04053497314453  accuracy3: 5.240301132202148  overall loss: 0.1736065298318863\n",
      "Epoch: 35  accuracy1: 50.43428039550781  accuracy2: 40.06948471069336  accuracy3: 5.269253253936768  overall loss: 0.1736673265695572\n",
      "Epoch: 36  accuracy1: 50.492183685302734  accuracy2: 40.04053497314453  accuracy3: 5.240301132202148  overall loss: 0.17363788187503815\n",
      "Epoch: 37  accuracy1: 50.52113723754883  accuracy2: 40.12738800048828  accuracy3: 5.269253253936768  overall loss: 0.17362695932388306\n",
      "Epoch    38: reducing learning rate of group 0 to 1.1719e-05.\n",
      "Epoch: 38  accuracy1: 50.57904052734375  accuracy2: 40.06948471069336  accuracy3: 5.269253253936768  overall loss: 0.1735764741897583\n",
      "Epoch: 39  accuracy1: 50.3474235534668  accuracy2: 40.06948471069336  accuracy3: 5.269253253936768  overall loss: 0.17376907169818878\n",
      "Epoch: 40  accuracy1: 50.57904052734375  accuracy2: 40.156341552734375  accuracy3: 5.269253253936768  overall loss: 0.17371699213981628\n",
      "saved modelsGraph.png\n",
      "Using device: cuda:0\n",
      "dense\n",
      "Epoch: 1  accuracy: 3.8795599937438965  loss: 0.2661023736000061\n",
      "Epoch: 2  accuracy: 3.155761480331421  loss: 0.26674219965934753\n",
      "Epoch: 3  accuracy: 3.0689055919647217  loss: 0.2659873366355896\n",
      "Epoch: 4  accuracy: 3.4452810287475586  loss: 0.2646487057209015\n",
      "Epoch: 5  accuracy: 3.618992567062378  loss: 0.26502034068107605\n",
      "Epoch: 6  accuracy: 3.9085118770599365  loss: 0.26458054780960083\n",
      "Epoch: 7  accuracy: 3.8506081104278564  loss: 0.2644880712032318\n",
      "Epoch     8: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 8  accuracy: 3.7637522220611572  loss: 0.2645695209503174\n",
      "Epoch: 9  accuracy: 3.9374639987945557  loss: 0.2642887830734253\n",
      "Epoch: 10  accuracy: 4.140127658843994  loss: 0.2641075849533081\n",
      "Epoch: 11  accuracy: 3.9953677654266357  loss: 0.2640906572341919\n",
      "Epoch: 12  accuracy: 4.226983547210693  loss: 0.26400813460350037\n",
      "Epoch: 13  accuracy: 4.313838958740234  loss: 0.26356303691864014\n",
      "Epoch: 14  accuracy: 4.603358745574951  loss: 0.26332685351371765\n",
      "Epoch: 15  accuracy: 4.719166278839111  loss: 0.26285648345947266\n",
      "Epoch: 16  accuracy: 4.7481184005737305  loss: 0.26240792870521545\n",
      "Epoch: 17  accuracy: 4.777070045471191  loss: 0.2618338167667389\n",
      "Epoch: 18  accuracy: 4.83497428894043  loss: 0.26127246022224426\n",
      "Epoch: 19  accuracy: 4.89287805557251  loss: 0.2608518600463867\n",
      "Epoch: 20  accuracy: 4.89287805557251  loss: 0.26066291332244873\n",
      "Epoch: 21  accuracy: 5.269253253936768  loss: 0.2591986060142517\n",
      "Epoch: 22  accuracy: 5.645628452301025  loss: 0.2593064308166504\n",
      "Epoch: 23  accuracy: 5.7035322189331055  loss: 0.258304625749588\n",
      "Epoch: 24  accuracy: 6.050955772399902  loss: 0.25689244270324707\n",
      "Epoch: 25  accuracy: 5.732484340667725  loss: 0.2577791213989258\n",
      "Epoch: 26  accuracy: 6.253619194030762  loss: 0.2560725212097168\n",
      "Epoch: 27  accuracy: 6.6299943923950195  loss: 0.2547692358493805\n",
      "Epoch: 28  accuracy: 6.6878981590271  loss: 0.2541339695453644\n",
      "Epoch: 29  accuracy: 7.0353217124938965  loss: 0.2535524368286133\n",
      "Epoch: 30  accuracy: 6.74580192565918  loss: 0.2535751163959503\n",
      "Epoch: 31  accuracy: 6.54313850402832  loss: 0.2527715861797333\n",
      "Epoch: 32  accuracy: 7.469600677490234  loss: 0.25110191106796265\n",
      "Epoch: 33  accuracy: 7.730168342590332  loss: 0.25077617168426514\n",
      "Epoch: 34  accuracy: 7.817023754119873  loss: 0.24911987781524658\n",
      "Epoch: 35  accuracy: 7.9907355308532715  loss: 0.24878010153770447\n",
      "Epoch: 36  accuracy: 8.048639297485352  loss: 0.24730893969535828\n",
      "Epoch: 37  accuracy: 7.9907355308532715  loss: 0.24777066707611084\n",
      "Epoch: 38  accuracy: 8.685582160949707  loss: 0.24574914574623108\n",
      "Epoch: 39  accuracy: 8.714533805847168  loss: 0.24490727484226227\n",
      "Epoch: 40  accuracy: 9.322525024414062  loss: 0.24340838193893433\n",
      "saved modelsGraph.png\n",
      "Using device: cuda:0\n",
      "dense_hier\n",
      "Epoch: 1  accuracy1: 37.463809967041016  accuracy2: 22.061378479003906  accuracy3: 3.9374639987945557  overall loss: 0.18021434545516968\n",
      "Epoch: 2  accuracy1: 39.085121154785156  accuracy2: 24.522293090820312  accuracy3: 4.574406623840332  overall loss: 0.17845164239406586\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-46c092ae49b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m          reproducibility = True, buildGraphs = True)\n\u001b[0;32m     11\u001b[0m train(\"dense_hier\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n\u001b[1;32m---> 12\u001b[1;33m          reproducibility = True, buildGraphs = True)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-a47792de00be>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(modelName, learning_rate, weightedHier, num_epochs, batch_size, dropout, reproducibility, buildGraphs, ckp_path)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"pose\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m                 \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"CNN\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"hier\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"hier2\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs\n",
    "\"\"\"\n",
    "#train models\n",
    "train(\"dense_combined1\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)\n",
    "train(\"dense_combined2\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)\n",
    "train(\"dense\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "dense_hier\n",
      "Epoch: 1  accuracy1: 37.463809967041016  accuracy2: 22.061378479003906  accuracy3: 3.9374639987945557  overall loss: 0.18021434545516968\n",
      "Epoch: 2  accuracy1: 39.085121154785156  accuracy2: 24.522293090820312  accuracy3: 4.574406623840332  overall loss: 0.17845164239406586\n",
      "Epoch: 3  accuracy1: 43.65952682495117  accuracy2: 28.25709342956543  accuracy3: 4.3427910804748535  overall loss: 0.17307797074317932\n",
      "Epoch: 4  accuracy1: 44.151710510253906  accuracy2: 29.646787643432617  accuracy3: 5.124493598937988  overall loss: 0.17268535494804382\n",
      "Epoch: 5  accuracy1: 40.2142448425293  accuracy2: 22.72727394104004  accuracy3: 3.705848455429077  overall loss: 0.1876976490020752\n",
      "Epoch: 6  accuracy1: 39.953678131103516  accuracy2: 25.477706909179688  accuracy3: 3.590040683746338  overall loss: 0.18564419448375702\n",
      "Epoch: 7  accuracy1: 47.539085388183594  accuracy2: 34.018531799316406  accuracy3: 4.863925933837891  overall loss: 0.16798044741153717\n",
      "Epoch: 8  accuracy1: 44.354373931884766  accuracy2: 29.009843826293945  accuracy3: 3.8216562271118164  overall loss: 0.18185660243034363\n",
      "Epoch: 9  accuracy1: 43.22524642944336  accuracy2: 27.359582901000977  accuracy3: 3.7927041053771973  overall loss: 0.19139498472213745\n",
      "Epoch: 10  accuracy1: 48.957733154296875  accuracy2: 32.397220611572266  accuracy3: 3.9374639987945557  overall loss: 0.1751461625099182\n",
      "Epoch    11: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 11  accuracy1: 48.3207893371582  accuracy2: 33.584251403808594  accuracy3: 4.863925933837891  overall loss: 0.1740778237581253\n",
      "Epoch: 12  accuracy1: 50.0  accuracy2: 36.62420654296875  accuracy3: 5.095541477203369  overall loss: 0.1708013266324997\n",
      "Epoch: 13  accuracy1: 48.89982604980469  accuracy2: 33.81586837768555  accuracy3: 4.89287805557251  overall loss: 0.1755957305431366\n",
      "Epoch: 14  accuracy1: 50.26057052612305  accuracy2: 37.14533996582031  accuracy3: 5.356109142303467  overall loss: 0.1718784123659134\n",
      "Epoch    15: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 15  accuracy1: 50.463233947753906  accuracy2: 36.7110595703125  accuracy3: 5.2113494873046875  overall loss: 0.17453260719776154\n",
      "Epoch: 16  accuracy1: 50.78170394897461  accuracy2: 38.12970733642578  accuracy3: 5.269253253936768  overall loss: 0.16950763761997223\n",
      "Epoch: 17  accuracy1: 51.071224212646484  accuracy2: 39.46149444580078  accuracy3: 5.153445243835449  overall loss: 0.16946198046207428\n",
      "Epoch: 18  accuracy1: 51.01332092285156  accuracy2: 39.374637603759766  accuracy3: 5.2113494873046875  overall loss: 0.1698487251996994\n",
      "Epoch    19: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 19  accuracy1: 51.129127502441406  accuracy2: 39.085121154785156  accuracy3: 5.240301132202148  overall loss: 0.17095641791820526\n",
      "Epoch: 20  accuracy1: 51.21598434448242  accuracy2: 39.5193977355957  accuracy3: 5.385060787200928  overall loss: 0.17024795711040497\n",
      "Epoch: 21  accuracy1: 51.30283737182617  accuracy2: 39.72206115722656  accuracy3: 5.385060787200928  overall loss: 0.17081595957279205\n",
      "Epoch: 22  accuracy1: 51.44759750366211  accuracy2: 39.60625457763672  accuracy3: 5.327157020568848  overall loss: 0.1711055338382721\n",
      "Epoch    23: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 23  accuracy1: 51.360740661621094  accuracy2: 39.5483512878418  accuracy3: 5.2982048988342285  overall loss: 0.1716255098581314\n",
      "Epoch: 24  accuracy1: 51.38969421386719  accuracy2: 39.8668212890625  accuracy3: 5.269253253936768  overall loss: 0.17114023864269257\n",
      "Epoch: 25  accuracy1: 51.38969421386719  accuracy2: 40.09843826293945  accuracy3: 5.356109142303467  overall loss: 0.17121613025665283\n",
      "Epoch: 26  accuracy1: 51.360740661621094  accuracy2: 40.06948471069336  accuracy3: 5.2982048988342285  overall loss: 0.17172640562057495\n",
      "Epoch    27: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 27  accuracy1: 51.38969421386719  accuracy2: 40.24319839477539  accuracy3: 5.327157020568848  overall loss: 0.17166142165660858\n",
      "Epoch: 28  accuracy1: 51.360740661621094  accuracy2: 40.18529510498047  accuracy3: 5.269253253936768  overall loss: 0.17176514863967896\n",
      "Epoch: 29  accuracy1: 51.360740661621094  accuracy2: 40.06948471069336  accuracy3: 5.2982048988342285  overall loss: 0.17187196016311646\n",
      "Epoch: 30  accuracy1: 51.50550079345703  accuracy2: 40.09843826293945  accuracy3: 5.240301132202148  overall loss: 0.1720093935728073\n",
      "Epoch    31: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 31  accuracy1: 51.38969421386719  accuracy2: 40.156341552734375  accuracy3: 5.269253253936768  overall loss: 0.17207777500152588\n",
      "Epoch: 32  accuracy1: 51.18703079223633  accuracy2: 40.27214813232422  accuracy3: 5.269253253936768  overall loss: 0.1721496433019638\n",
      "Epoch: 33  accuracy1: 51.158077239990234  accuracy2: 40.27214813232422  accuracy3: 5.356109142303467  overall loss: 0.17211467027664185\n",
      "Epoch: 34  accuracy1: 51.534454345703125  accuracy2: 40.30110168457031  accuracy3: 5.327157020568848  overall loss: 0.1721930056810379\n",
      "Epoch    35: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 35  accuracy1: 51.38969421386719  accuracy2: 40.2142448425293  accuracy3: 5.269253253936768  overall loss: 0.1722782403230667\n",
      "Epoch: 36  accuracy1: 51.534454345703125  accuracy2: 40.156341552734375  accuracy3: 5.327157020568848  overall loss: 0.17233285307884216\n",
      "Epoch: 37  accuracy1: 51.331790924072266  accuracy2: 40.156341552734375  accuracy3: 5.327157020568848  overall loss: 0.17235620319843292\n",
      "Epoch: 38  accuracy1: 51.41864776611328  accuracy2: 40.24319839477539  accuracy3: 5.327157020568848  overall loss: 0.1723233014345169\n",
      "Epoch    39: reducing learning rate of group 0 to 1.1719e-05.\n",
      "Epoch: 39  accuracy1: 51.331790924072266  accuracy2: 40.156341552734375  accuracy3: 5.327157020568848  overall loss: 0.1723042130470276\n",
      "Epoch: 40  accuracy1: 51.360740661621094  accuracy2: 40.27214813232422  accuracy3: 5.327157020568848  overall loss: 0.1724168062210083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"dense_hier\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "dense_combined1\n",
      "Epoch: 3  accuracy1: 34.94499206542969  accuracy2: 20.121599197387695  accuracy3: 11.957151412963867  overall loss: 0.1697954684495926\n",
      "Epoch: 4  accuracy1: 42.067169189453125  accuracy2: 23.885351181030273  accuracy3: 15.489288330078125  overall loss: 0.15953503549098969\n",
      "Epoch: 5  accuracy1: 42.7041130065918  accuracy2: 26.34626579284668  accuracy3: 18.008106231689453  overall loss: 0.1567986011505127\n",
      "Epoch     6: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 6  accuracy1: 43.6884765625  accuracy2: 27.533294677734375  accuracy3: 19.658367156982422  overall loss: 0.15303201973438263\n",
      "Epoch: 7  accuracy1: 42.79096984863281  accuracy2: 27.967575073242188  accuracy3: 22.292993545532227  overall loss: 0.15093636512756348\n",
      "Epoch: 8  accuracy1: 45.888824462890625  accuracy2: 33.584251403808594  accuracy3: 23.972206115722656  overall loss: 0.14508391916751862\n",
      "Epoch: 9  accuracy1: 45.36769104003906  accuracy2: 32.5419807434082  accuracy3: 24.69600486755371  overall loss: 0.14506970345973969\n",
      "Epoch    10: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 10  accuracy1: 45.888824462890625  accuracy2: 33.2368278503418  accuracy3: 24.580198287963867  overall loss: 0.1466604322195053\n",
      "Epoch: 11  accuracy1: 47.10480880737305  accuracy2: 35.755645751953125  accuracy3: 26.14360237121582  overall loss: 0.14254000782966614\n",
      "Epoch: 12  accuracy1: 47.596988677978516  accuracy2: 36.30573272705078  accuracy3: 26.635786056518555  overall loss: 0.1418018341064453\n",
      "Epoch: 13  accuracy1: 47.48118209838867  accuracy2: 36.30573272705078  accuracy3: 26.896352767944336  overall loss: 0.14238178730010986\n",
      "Epoch    14: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 14  accuracy1: 46.84423828125  accuracy2: 36.740013122558594  accuracy3: 27.330631256103516  overall loss: 0.14281243085861206\n",
      "Epoch: 15  accuracy1: 47.539085388183594  accuracy2: 37.000579833984375  accuracy3: 27.938623428344727  overall loss: 0.14154134690761566\n",
      "Epoch: 16  accuracy1: 48.176029205322266  accuracy2: 37.17428970336914  accuracy3: 28.199190139770508  overall loss: 0.14147347211837769\n",
      "Epoch: 17  accuracy1: 48.08917236328125  accuracy2: 37.52171325683594  accuracy3: 28.372901916503906  overall loss: 0.1416027545928955\n",
      "Epoch    18: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 18  accuracy1: 48.55240249633789  accuracy2: 37.34800338745117  accuracy3: 28.546613693237305  overall loss: 0.1421036273241043\n",
      "Epoch: 19  accuracy1: 48.49449920654297  accuracy2: 37.34800338745117  accuracy3: 28.691373825073242  overall loss: 0.14106550812721252\n",
      "Epoch: 20  accuracy1: 48.581356048583984  accuracy2: 37.376956939697266  accuracy3: 28.807180404663086  overall loss: 0.14108620584011078\n",
      "Epoch: 21  accuracy1: 48.49449920654297  accuracy2: 37.463809967041016  accuracy3: 28.749277114868164  overall loss: 0.1413184255361557\n",
      "Epoch    22: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 22  accuracy1: 48.784019470214844  accuracy2: 37.52171325683594  accuracy3: 28.807180404663086  overall loss: 0.14153370261192322\n",
      "Epoch: 23  accuracy1: 48.668212890625  accuracy2: 37.69542694091797  accuracy3: 29.994211196899414  overall loss: 0.14094989001750946\n",
      "Epoch: 24  accuracy1: 48.668212890625  accuracy2: 37.405906677246094  accuracy3: 29.93630599975586  overall loss: 0.14105388522148132\n",
      "Epoch: 25  accuracy1: 48.75506591796875  accuracy2: 37.579620361328125  accuracy3: 30.052114486694336  overall loss: 0.14112411439418793\n",
      "Epoch    26: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 26  accuracy1: 48.72611618041992  accuracy2: 37.55066680908203  accuracy3: 29.994211196899414  overall loss: 0.14107750356197357\n",
      "Epoch: 27  accuracy1: 48.89982604980469  accuracy2: 37.63752365112305  accuracy3: 30.283729553222656  overall loss: 0.1409313976764679\n",
      "Epoch: 28  accuracy1: 49.07353973388672  accuracy2: 37.666473388671875  accuracy3: 30.312681198120117  overall loss: 0.14094460010528564\n",
      "Epoch: 29  accuracy1: 48.9866828918457  accuracy2: 37.60857009887695  accuracy3: 30.370586395263672  overall loss: 0.14089390635490417\n",
      "Epoch    30: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 30  accuracy1: 48.9866828918457  accuracy2: 37.92704391479492  accuracy3: 30.283729553222656  overall loss: 0.14090228080749512\n",
      "Epoch: 31  accuracy1: 49.247249603271484  accuracy2: 37.840187072753906  accuracy3: 30.225826263427734  overall loss: 0.14089249074459076\n",
      "Epoch: 32  accuracy1: 49.18934631347656  accuracy2: 37.869136810302734  accuracy3: 30.225826263427734  overall loss: 0.14093272387981415\n",
      "Epoch: 33  accuracy1: 49.13144302368164  accuracy2: 37.869136810302734  accuracy3: 30.196874618530273  overall loss: 0.14080962538719177\n",
      "Epoch    34: reducing learning rate of group 0 to 1.1719e-05.\n",
      "Epoch: 34  accuracy1: 49.160396575927734  accuracy2: 37.840187072753906  accuracy3: 30.283729553222656  overall loss: 0.1409262716770172\n",
      "Epoch: 35  accuracy1: 49.044586181640625  accuracy2: 37.89809036254883  accuracy3: 30.13896942138672  overall loss: 0.14082972705364227\n",
      "Epoch: 36  accuracy1: 49.218299865722656  accuracy2: 37.95599365234375  accuracy3: 30.110017776489258  overall loss: 0.14080926775932312\n",
      "Epoch: 37  accuracy1: 49.218299865722656  accuracy2: 37.984947204589844  accuracy3: 30.13896942138672  overall loss: 0.14084944128990173\n",
      "Epoch    38: reducing learning rate of group 0 to 5.8594e-06.\n",
      "Epoch: 38  accuracy1: 49.218299865722656  accuracy2: 37.869136810302734  accuracy3: 30.13896942138672  overall loss: 0.14092907309532166\n",
      "Epoch: 39  accuracy1: 49.247249603271484  accuracy2: 37.75333023071289  accuracy3: 30.110017776489258  overall loss: 0.140902578830719\n",
      "Epoch: 40  accuracy1: 49.160396575927734  accuracy2: 37.869136810302734  accuracy3: 30.16792106628418  overall loss: 0.14087632298469543\n",
      "Epoch: 41  accuracy1: 49.10248947143555  accuracy2: 37.782283782958984  accuracy3: 30.196874618530273  overall loss: 0.1409674435853958\n",
      "Epoch    42: reducing learning rate of group 0 to 2.9297e-06.\n",
      "Epoch: 42  accuracy1: 49.044586181640625  accuracy2: 37.840187072753906  accuracy3: 30.16792106628418  overall loss: 0.14092104136943817\n",
      "Epoch: 43  accuracy1: 49.044586181640625  accuracy2: 37.89809036254883  accuracy3: 30.254777908325195  overall loss: 0.14084282517433167\n",
      "Epoch: 44  accuracy1: 49.07353973388672  accuracy2: 37.69542694091797  accuracy3: 30.225826263427734  overall loss: 0.14088809490203857\n",
      "Epoch: 45  accuracy1: 49.10248947143555  accuracy2: 37.869136810302734  accuracy3: 30.225826263427734  overall loss: 0.14089401066303253\n",
      "Epoch    46: reducing learning rate of group 0 to 1.4648e-06.\n",
      "Epoch: 46  accuracy1: 49.10248947143555  accuracy2: 37.92704391479492  accuracy3: 30.225826263427734  overall loss: 0.1409059464931488\n",
      "Epoch: 47  accuracy1: 49.10248947143555  accuracy2: 37.840187072753906  accuracy3: 30.283729553222656  overall loss: 0.14088553190231323\n",
      "Epoch: 48  accuracy1: 49.07353973388672  accuracy2: 37.840187072753906  accuracy3: 30.225826263427734  overall loss: 0.14093729853630066\n",
      "Epoch: 49  accuracy1: 49.10248947143555  accuracy2: 37.840187072753906  accuracy3: 30.254777908325195  overall loss: 0.14089739322662354\n",
      "Epoch    50: reducing learning rate of group 0 to 7.3242e-07.\n",
      "Epoch: 50  accuracy1: 49.0156364440918  accuracy2: 37.840187072753906  accuracy3: 30.283729553222656  overall loss: 0.14087450504302979\n",
      "Epoch: 51  accuracy1: 49.07353973388672  accuracy2: 37.81123352050781  accuracy3: 30.312681198120117  overall loss: 0.14091700315475464\n",
      "Epoch: 52  accuracy1: 49.10248947143555  accuracy2: 37.840187072753906  accuracy3: 30.312681198120117  overall loss: 0.14086876809597015\n",
      "Epoch: 53  accuracy1: 49.044586181640625  accuracy2: 37.782283782958984  accuracy3: 30.283729553222656  overall loss: 0.14095929265022278\n",
      "Epoch    54: reducing learning rate of group 0 to 3.6621e-07.\n",
      "Epoch: 54  accuracy1: 49.0156364440918  accuracy2: 37.869136810302734  accuracy3: 30.283729553222656  overall loss: 0.1408742517232895\n",
      "Epoch: 55  accuracy1: 49.07353973388672  accuracy2: 37.89809036254883  accuracy3: 30.254777908325195  overall loss: 0.14088936150074005\n",
      "Epoch: 56  accuracy1: 49.07353973388672  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14089834690093994\n",
      "Epoch: 57  accuracy1: 49.044586181640625  accuracy2: 37.869136810302734  accuracy3: 30.312681198120117  overall loss: 0.14091911911964417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    58: reducing learning rate of group 0 to 1.8311e-07.\n",
      "Epoch: 58  accuracy1: 49.07353973388672  accuracy2: 37.89809036254883  accuracy3: 30.312681198120117  overall loss: 0.14087139070034027\n",
      "Epoch: 59  accuracy1: 49.044586181640625  accuracy2: 37.840187072753906  accuracy3: 30.312681198120117  overall loss: 0.14089810848236084\n",
      "Epoch: 60  accuracy1: 49.07353973388672  accuracy2: 37.92704391479492  accuracy3: 30.283729553222656  overall loss: 0.14088718593120575\n",
      "Epoch: 61  accuracy1: 49.044586181640625  accuracy2: 37.869136810302734  accuracy3: 30.341632843017578  overall loss: 0.14086836576461792\n",
      "Epoch    62: reducing learning rate of group 0 to 9.1553e-08.\n",
      "Epoch: 62  accuracy1: 49.0156364440918  accuracy2: 37.92704391479492  accuracy3: 30.254777908325195  overall loss: 0.14086119830608368\n",
      "Epoch: 63  accuracy1: 49.13144302368164  accuracy2: 37.782283782958984  accuracy3: 30.283729553222656  overall loss: 0.14094345271587372\n",
      "Epoch: 64  accuracy1: 49.044586181640625  accuracy2: 37.869136810302734  accuracy3: 30.341632843017578  overall loss: 0.1408735066652298\n",
      "Epoch: 65  accuracy1: 49.07353973388672  accuracy2: 37.984947204589844  accuracy3: 30.254777908325195  overall loss: 0.1408482789993286\n",
      "Epoch    66: reducing learning rate of group 0 to 4.5776e-08.\n",
      "Epoch: 66  accuracy1: 49.044586181640625  accuracy2: 37.92704391479492  accuracy3: 30.254777908325195  overall loss: 0.14090648293495178\n",
      "Epoch: 67  accuracy1: 49.07353973388672  accuracy2: 37.92704391479492  accuracy3: 30.283729553222656  overall loss: 0.14088700711727142\n",
      "Epoch: 68  accuracy1: 49.10248947143555  accuracy2: 37.75333023071289  accuracy3: 30.283729553222656  overall loss: 0.14090248942375183\n",
      "Epoch: 69  accuracy1: 49.160396575927734  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14092455804347992\n",
      "Epoch    70: reducing learning rate of group 0 to 2.2888e-08.\n",
      "Epoch: 70  accuracy1: 49.160396575927734  accuracy2: 37.840187072753906  accuracy3: 30.312681198120117  overall loss: 0.14090979099273682\n",
      "Epoch: 71  accuracy1: 48.9866828918457  accuracy2: 37.840187072753906  accuracy3: 30.312681198120117  overall loss: 0.1408865600824356\n",
      "Epoch: 72  accuracy1: 49.044586181640625  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14089573919773102\n",
      "Epoch: 73  accuracy1: 49.044586181640625  accuracy2: 37.92704391479492  accuracy3: 30.341632843017578  overall loss: 0.1408945769071579\n",
      "Epoch    74: reducing learning rate of group 0 to 1.1444e-08.\n",
      "Epoch: 74  accuracy1: 49.044586181640625  accuracy2: 37.840187072753906  accuracy3: 30.283729553222656  overall loss: 0.14090242981910706\n",
      "Epoch: 75  accuracy1: 49.10248947143555  accuracy2: 37.95599365234375  accuracy3: 30.254777908325195  overall loss: 0.1408141404390335\n",
      "Epoch: 76  accuracy1: 49.044586181640625  accuracy2: 37.69542694091797  accuracy3: 30.312681198120117  overall loss: 0.140911266207695\n",
      "Epoch: 77  accuracy1: 49.07353973388672  accuracy2: 37.92704391479492  accuracy3: 30.312681198120117  overall loss: 0.14084674417972565\n",
      "Epoch: 78  accuracy1: 49.07353973388672  accuracy2: 37.89809036254883  accuracy3: 30.283729553222656  overall loss: 0.14086715877056122\n",
      "Epoch: 79  accuracy1: 49.0156364440918  accuracy2: 37.869136810302734  accuracy3: 30.312681198120117  overall loss: 0.14089877903461456\n",
      "Epoch: 80  accuracy1: 49.0156364440918  accuracy2: 37.75333023071289  accuracy3: 30.254777908325195  overall loss: 0.14090077579021454\n",
      "Epoch: 81  accuracy1: 49.044586181640625  accuracy2: 37.92704391479492  accuracy3: 30.312681198120117  overall loss: 0.14087586104869843\n",
      "Epoch: 82  accuracy1: 49.044586181640625  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14091195166110992\n",
      "Epoch: 83  accuracy1: 49.13144302368164  accuracy2: 37.869136810302734  accuracy3: 30.283729553222656  overall loss: 0.14089080691337585\n",
      "Epoch: 84  accuracy1: 49.10248947143555  accuracy2: 37.92704391479492  accuracy3: 30.283729553222656  overall loss: 0.140860915184021\n",
      "Epoch: 85  accuracy1: 49.044586181640625  accuracy2: 37.7243766784668  accuracy3: 30.254777908325195  overall loss: 0.14091436564922333\n",
      "Epoch: 86  accuracy1: 49.044586181640625  accuracy2: 37.984947204589844  accuracy3: 30.254777908325195  overall loss: 0.14087556302547455\n",
      "Epoch: 87  accuracy1: 49.0156364440918  accuracy2: 37.89809036254883  accuracy3: 30.283729553222656  overall loss: 0.140898659825325\n",
      "Epoch: 88  accuracy1: 49.0156364440918  accuracy2: 37.869136810302734  accuracy3: 30.341632843017578  overall loss: 0.14089880883693695\n",
      "Epoch: 89  accuracy1: 49.044586181640625  accuracy2: 37.81123352050781  accuracy3: 30.312681198120117  overall loss: 0.14089447259902954\n",
      "Epoch: 90  accuracy1: 49.10248947143555  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14095057547092438\n",
      "Epoch: 91  accuracy1: 49.10248947143555  accuracy2: 37.81123352050781  accuracy3: 30.283729553222656  overall loss: 0.14093512296676636\n",
      "Epoch: 92  accuracy1: 49.10248947143555  accuracy2: 37.92704391479492  accuracy3: 30.283729553222656  overall loss: 0.14085297286510468\n",
      "Epoch: 93  accuracy1: 49.0156364440918  accuracy2: 37.95599365234375  accuracy3: 30.283729553222656  overall loss: 0.14086180925369263\n",
      "Epoch: 94  accuracy1: 49.13144302368164  accuracy2: 37.95599365234375  accuracy3: 30.312681198120117  overall loss: 0.14085517823696136\n",
      "Epoch: 95  accuracy1: 49.13144302368164  accuracy2: 37.869136810302734  accuracy3: 30.254777908325195  overall loss: 0.14088821411132812\n",
      "Epoch: 96  accuracy1: 49.044586181640625  accuracy2: 37.869136810302734  accuracy3: 30.283729553222656  overall loss: 0.14090000092983246\n",
      "Epoch: 97  accuracy1: 49.07353973388672  accuracy2: 37.782283782958984  accuracy3: 30.283729553222656  overall loss: 0.14098495244979858\n",
      "Epoch: 98  accuracy1: 49.0156364440918  accuracy2: 37.81123352050781  accuracy3: 30.312681198120117  overall loss: 0.14088037610054016\n",
      "Epoch: 99  accuracy1: 49.044586181640625  accuracy2: 37.782283782958984  accuracy3: 30.312681198120117  overall loss: 0.14088769257068634\n",
      "Epoch: 100  accuracy1: 49.044586181640625  accuracy2: 37.89809036254883  accuracy3: 30.254777908325195  overall loss: 0.1408882588148117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"dense_combined1\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 100, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True, ckp_path = \"./checkpoints/dense_combined1_0.003_0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "cnn\n",
      "Epoch: 1  accuracy: 14.44701862335205  loss: 0.22817900776863098\n",
      "Epoch: 2  accuracy: 22.177186965942383  loss: 0.19990171492099762\n",
      "Epoch: 3  accuracy: 27.909669876098633  loss: 0.18494626879692078\n",
      "Epoch: 4  accuracy: 28.778228759765625  loss: 0.18209215998649597\n",
      "Epoch: 5  accuracy: 32.194557189941406  loss: 0.17134562134742737\n",
      "Epoch: 6  accuracy: 34.85813522338867  loss: 0.16671264171600342\n",
      "Epoch: 7  accuracy: 35.552982330322266  loss: 0.16321682929992676\n",
      "Epoch: 8  accuracy: 35.06079864501953  loss: 0.1666542887687683\n",
      "Epoch: 9  accuracy: 35.78459930419922  loss: 0.16289980709552765\n",
      "Epoch: 10  accuracy: 37.02953338623047  loss: 0.1642378717660904\n",
      "Epoch: 11  accuracy: 38.30341720581055  loss: 0.16358496248722076\n",
      "Epoch: 12  accuracy: 38.01389694213867  loss: 0.17050673067569733\n",
      "Epoch    13: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 13  accuracy: 37.69542694091797  loss: 0.17087312042713165\n",
      "Epoch: 14  accuracy: 41.71974563598633  loss: 0.16456559300422668\n",
      "Epoch: 15  accuracy: 42.067169189453125  loss: 0.16997207701206207\n",
      "Epoch: 16  accuracy: 42.0382194519043  loss: 0.1739400029182434\n",
      "Epoch    17: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 17  accuracy: 41.6907958984375  loss: 0.1785741001367569\n",
      "Epoch: 18  accuracy: 43.92009353637695  loss: 0.17832575738430023\n",
      "Epoch: 19  accuracy: 44.383323669433594  loss: 0.18105769157409668\n",
      "Epoch: 20  accuracy: 43.45686340332031  loss: 0.18564319610595703\n",
      "Epoch    21: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 21  accuracy: 44.06485366821289  loss: 0.19015520811080933\n",
      "Epoch: 22  accuracy: 45.30978775024414  loss: 0.18856549263000488\n",
      "Epoch: 23  accuracy: 45.25188446044922  loss: 0.19152861833572388\n",
      "Epoch: 24  accuracy: 45.425594329833984  loss: 0.19317547976970673\n",
      "Epoch    25: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 25  accuracy: 45.19397735595703  loss: 0.1961507350206375\n",
      "Epoch: 26  accuracy: 45.45454788208008  loss: 0.19696861505508423\n",
      "Epoch: 27  accuracy: 45.77301788330078  loss: 0.1979271024465561\n",
      "Epoch: 28  accuracy: 45.801971435546875  loss: 0.19879886507987976\n",
      "Epoch    29: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 29  accuracy: 45.686161041259766  loss: 0.19959403574466705\n",
      "Epoch: 30  accuracy: 46.091487884521484  loss: 0.2002497911453247\n",
      "Epoch: 31  accuracy: 46.32310485839844  loss: 0.20054593682289124\n",
      "Epoch: 32  accuracy: 46.1783447265625  loss: 0.2011907547712326\n",
      "Epoch    33: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 33  accuracy: 45.8598747253418  loss: 0.20177561044692993\n",
      "Epoch: 34  accuracy: 46.4968147277832  loss: 0.2018233686685562\n",
      "Epoch: 35  accuracy: 46.12044143676758  loss: 0.202374666929245\n",
      "Epoch: 36  accuracy: 46.38100814819336  loss: 0.20313522219657898\n",
      "Epoch    37: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 37  accuracy: 46.207298278808594  loss: 0.20281419157981873\n",
      "Epoch: 38  accuracy: 46.265201568603516  loss: 0.202739879488945\n",
      "Epoch: 39  accuracy: 46.43891143798828  loss: 0.2032323181629181\n",
      "Epoch: 40  accuracy: 46.23624801635742  loss: 0.20355308055877686\n",
      "Using device: cuda:0\n",
      "hier\n",
      "Epoch: 1  accuracy1: 42.6751594543457  accuracy2: 26.230457305908203  accuracy3: 13.08627700805664  overall loss: 0.1604590117931366\n",
      "Epoch: 2  accuracy1: 42.733062744140625  accuracy2: 31.23914337158203  accuracy3: 19.976839065551758  overall loss: 0.14808523654937744\n",
      "Epoch: 3  accuracy1: 47.42327880859375  accuracy2: 36.7110595703125  accuracy3: 25.361900329589844  overall loss: 0.13677331805229187\n",
      "Epoch: 4  accuracy1: 47.88650894165039  accuracy2: 38.39027404785156  accuracy3: 28.691373825073242  overall loss: 0.13143284618854523\n",
      "Epoch: 5  accuracy1: 48.49449920654297  accuracy2: 41.661842346191406  accuracy3: 31.036479949951172  overall loss: 0.1256769895553589\n",
      "Epoch: 6  accuracy1: 49.76838684082031  accuracy2: 42.96467971801758  accuracy3: 33.26578140258789  overall loss: 0.1214132159948349\n",
      "Epoch: 7  accuracy1: 48.52345275878906  accuracy2: 43.0225830078125  accuracy3: 33.78691482543945  overall loss: 0.1239238902926445\n",
      "Epoch: 8  accuracy1: 49.47886657714844  accuracy2: 45.77301788330078  accuracy3: 37.376956939697266  overall loss: 0.11873432993888855\n",
      "Epoch: 9  accuracy1: 52.4898681640625  accuracy2: 47.36537551879883  accuracy3: 37.81123352050781  overall loss: 0.11596795171499252\n",
      "Epoch: 10  accuracy1: 48.841922760009766  accuracy2: 46.96004867553711  accuracy3: 38.67979431152344  overall loss: 0.11685121804475784\n",
      "Epoch: 11  accuracy1: 51.04227066040039  accuracy2: 47.68384552001953  accuracy3: 39.22987747192383  overall loss: 0.11698804050683975\n",
      "Epoch: 12  accuracy1: 52.460914611816406  accuracy2: 46.84423828125  accuracy3: 39.374637603759766  overall loss: 0.11841430515050888\n",
      "Epoch    13: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 13  accuracy1: 50.43428039550781  accuracy2: 49.79733657836914  accuracy3: 39.60625457763672  overall loss: 0.11894077807664871\n",
      "Epoch: 14  accuracy1: 52.8372917175293  accuracy2: 51.04227066040039  accuracy3: 42.327735900878906  overall loss: 0.11606890708208084\n",
      "Epoch: 15  accuracy1: 53.53213882446289  accuracy2: 51.65026092529297  accuracy3: 43.08048629760742  overall loss: 0.11643186211585999\n",
      "Epoch: 16  accuracy1: 53.15576171875  accuracy2: 51.534454345703125  accuracy3: 43.45686340332031  overall loss: 0.11960546672344208\n",
      "Epoch    17: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 17  accuracy1: 54.45859909057617  accuracy2: 52.200347900390625  accuracy3: 42.6751594543457  overall loss: 0.12018335610628128\n",
      "Epoch: 18  accuracy1: 54.54545593261719  accuracy2: 54.284889221191406  accuracy3: 45.10712432861328  overall loss: 0.11856210976839066\n",
      "Epoch: 19  accuracy1: 55.153446197509766  accuracy2: 54.57440948486328  accuracy3: 44.643890380859375  overall loss: 0.12037289142608643\n",
      "Epoch: 20  accuracy1: 56.05095672607422  accuracy2: 54.57440948486328  accuracy3: 45.020267486572266  overall loss: 0.12085302174091339\n",
      "Epoch    21: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 21  accuracy1: 56.224666595458984  accuracy2: 54.80602264404297  accuracy3: 45.483497619628906  overall loss: 0.12228358536958694\n",
      "Epoch: 22  accuracy1: 56.68790054321289  accuracy2: 55.9640998840332  accuracy3: 45.628257751464844  overall loss: 0.12135913223028183\n",
      "Epoch: 23  accuracy1: 56.74580383300781  accuracy2: 55.153446197509766  accuracy3: 46.207298278808594  overall loss: 0.12156251072883606\n",
      "Epoch: 24  accuracy1: 56.74580383300781  accuracy2: 55.06658935546875  accuracy3: 46.14939498901367  overall loss: 0.12167781591415405\n",
      "Epoch    25: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 25  accuracy1: 56.51418685913086  accuracy2: 55.58772659301758  accuracy3: 46.467864990234375  overall loss: 0.12242445349693298\n",
      "Epoch: 26  accuracy1: 57.064273834228516  accuracy2: 56.05095672607422  accuracy3: 46.43891143798828  overall loss: 0.12322230637073517\n",
      "Epoch: 27  accuracy1: 56.74580383300781  accuracy2: 56.16676330566406  accuracy3: 47.07585525512695  overall loss: 0.12373530119657516\n",
      "Epoch: 28  accuracy1: 57.03532409667969  accuracy2: 56.16676330566406  accuracy3: 46.69947814941406  overall loss: 0.1240638792514801\n",
      "Epoch    29: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 29  accuracy1: 56.89056396484375  accuracy2: 56.16676330566406  accuracy3: 46.670528411865234  overall loss: 0.12462040036916733\n",
      "Epoch: 30  accuracy1: 57.266937255859375  accuracy2: 55.732486724853516  accuracy3: 47.133758544921875  overall loss: 0.1244402751326561\n",
      "Epoch: 31  accuracy1: 57.180084228515625  accuracy2: 56.10886001586914  accuracy3: 46.43891143798828  overall loss: 0.12484878301620483\n",
      "Epoch: 32  accuracy1: 57.266937255859375  accuracy2: 56.16676330566406  accuracy3: 46.75738525390625  overall loss: 0.12536154687404633\n",
      "Epoch    33: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 33  accuracy1: 57.15113067626953  accuracy2: 56.07991027832031  accuracy3: 46.61262512207031  overall loss: 0.12544937431812286\n",
      "Epoch: 34  accuracy1: 57.70121765136719  accuracy2: 55.9640998840332  accuracy3: 46.64157485961914  overall loss: 0.12528657913208008\n",
      "Epoch: 35  accuracy1: 57.845977783203125  accuracy2: 56.195716857910156  accuracy3: 46.84423828125  overall loss: 0.12528637051582336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36  accuracy1: 57.75912094116211  accuracy2: 56.07991027832031  accuracy3: 46.81528854370117  overall loss: 0.12544327974319458\n",
      "Epoch    37: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 37  accuracy1: 57.90388107299805  accuracy2: 56.195716857910156  accuracy3: 47.133758544921875  overall loss: 0.12557461857795715\n",
      "Epoch: 38  accuracy1: 58.048641204833984  accuracy2: 56.10886001586914  accuracy3: 46.81528854370117  overall loss: 0.12534838914871216\n",
      "Epoch: 39  accuracy1: 58.048641204833984  accuracy2: 56.340476989746094  accuracy3: 47.04690170288086  overall loss: 0.12549743056297302\n",
      "Epoch: 40  accuracy1: 57.75912094116211  accuracy2: 56.25362014770508  accuracy3: 47.10480880737305  overall loss: 0.1256469041109085\n",
      "Using device: cuda:0\n",
      "combined1\n",
      "Epoch: 1  accuracy1: 39.5483512878418  accuracy2: 21.598148345947266  accuracy3: 6.079907417297363  overall loss: 0.17182067036628723\n",
      "Epoch: 2  accuracy1: 45.39664077758789  accuracy2: 30.225826263427734  accuracy3: 13.665315628051758  overall loss: 0.1532624512910843\n",
      "Epoch: 3  accuracy1: 46.75738525390625  accuracy2: 32.976261138916016  accuracy3: 15.257672309875488  overall loss: 0.14366041123867035\n",
      "Epoch: 4  accuracy1: 48.92877960205078  accuracy2: 35.350318908691406  accuracy3: 18.442386627197266  overall loss: 0.1378018707036972\n",
      "Epoch: 5  accuracy1: 50.17371368408203  accuracy2: 38.41922378540039  accuracy3: 23.306312561035156  overall loss: 0.13224031031131744\n",
      "Epoch: 6  accuracy1: 50.694847106933594  accuracy2: 41.16965866088867  accuracy3: 27.070064544677734  overall loss: 0.12608754634857178\n",
      "Epoch: 7  accuracy1: 50.05790328979492  accuracy2: 41.95136260986328  accuracy3: 29.0677490234375  overall loss: 0.12329000979661942\n",
      "Epoch: 8  accuracy1: 51.18703079223633  accuracy2: 43.0225830078125  accuracy3: 31.47075843811035  overall loss: 0.12103158980607986\n",
      "Epoch: 9  accuracy1: 51.331790924072266  accuracy2: 43.60162353515625  accuracy3: 32.42617416381836  overall loss: 0.12067247927188873\n",
      "Epoch: 10  accuracy1: 52.08454132080078  accuracy2: 45.888824462890625  accuracy3: 34.45280838012695  overall loss: 0.1171686202287674\n",
      "Epoch: 11  accuracy1: 51.360740661621094  accuracy2: 45.25188446044922  accuracy3: 35.755645751953125  overall loss: 0.12062103301286697\n",
      "Epoch: 12  accuracy1: 50.550086975097656  accuracy2: 44.58598709106445  accuracy3: 36.3636360168457  overall loss: 0.11961518228054047\n",
      "Epoch: 13  accuracy1: 51.85292434692383  accuracy2: 47.915462493896484  accuracy3: 37.89809036254883  overall loss: 0.11874911934137344\n",
      "Epoch    14: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 14  accuracy1: 51.21598434448242  accuracy2: 46.931095123291016  accuracy3: 36.56629943847656  overall loss: 0.12194585800170898\n",
      "Epoch: 15  accuracy1: 54.979736328125  accuracy2: 50.086856842041016  accuracy3: 39.577301025390625  overall loss: 0.11725180596113205\n",
      "Epoch: 16  accuracy1: 52.95309829711914  accuracy2: 49.623626708984375  accuracy3: 40.70642852783203  overall loss: 0.12111373990774155\n",
      "Epoch: 17  accuracy1: 53.96641540527344  accuracy2: 51.18703079223633  accuracy3: 40.59062194824219  overall loss: 0.12083831429481506\n",
      "Epoch    18: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 18  accuracy1: 52.605674743652344  accuracy2: 49.79733657836914  accuracy3: 39.80891799926758  overall loss: 0.12559305131435394\n",
      "Epoch: 19  accuracy1: 55.761436462402344  accuracy2: 52.43196487426758  accuracy3: 42.61725616455078  overall loss: 0.12062309682369232\n",
      "Epoch: 20  accuracy1: 55.935150146484375  accuracy2: 52.403011322021484  accuracy3: 42.530399322509766  overall loss: 0.12271393835544586\n",
      "Epoch: 21  accuracy1: 55.90619659423828  accuracy2: 52.11349105834961  accuracy3: 42.21192932128906  overall loss: 0.12385580688714981\n",
      "Epoch    22: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 22  accuracy1: 56.42733383178711  accuracy2: 52.22930145263672  accuracy3: 41.92240905761719  overall loss: 0.12602531909942627\n",
      "Epoch: 23  accuracy1: 57.41169738769531  accuracy2: 52.54777145385742  accuracy3: 43.775333404541016  overall loss: 0.1266419142484665\n",
      "Epoch: 24  accuracy1: 57.49855422973633  accuracy2: 52.75043487548828  accuracy3: 43.19629669189453  overall loss: 0.12705151736736298\n",
      "Epoch: 25  accuracy1: 57.09322738647461  accuracy2: 53.15576171875  accuracy3: 43.86219024658203  overall loss: 0.1282843053340912\n",
      "Epoch    26: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 26  accuracy1: 58.01968765258789  accuracy2: 52.95309829711914  accuracy3: 42.96467971801758  overall loss: 0.13169795274734497\n",
      "Epoch: 27  accuracy1: 59.090911865234375  accuracy2: 53.445281982421875  accuracy3: 44.0359001159668  overall loss: 0.13101480901241302\n",
      "Epoch: 28  accuracy1: 58.106544494628906  accuracy2: 53.01100158691406  accuracy3: 43.54372024536133  overall loss: 0.1322854459285736\n",
      "Epoch: 29  accuracy1: 58.917198181152344  accuracy2: 53.618995666503906  accuracy3: 44.00695037841797  overall loss: 0.13222868740558624\n",
      "Epoch    30: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 30  accuracy1: 58.251304626464844  accuracy2: 53.59004211425781  accuracy3: 43.572669982910156  overall loss: 0.1333482265472412\n",
      "Epoch: 31  accuracy1: 58.39606475830078  accuracy2: 54.05327224731445  accuracy3: 44.0359001159668  overall loss: 0.13296964764595032\n",
      "Epoch: 32  accuracy1: 58.714534759521484  accuracy2: 53.99536895751953  accuracy3: 43.65952682495117  overall loss: 0.13350342214107513\n",
      "Epoch: 33  accuracy1: 58.54082489013672  accuracy2: 53.5031852722168  accuracy3: 43.45686340332031  overall loss: 0.1342814415693283\n",
      "Epoch    34: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 34  accuracy1: 58.714534759521484  accuracy2: 53.79270553588867  accuracy3: 43.28314971923828  overall loss: 0.13526254892349243\n",
      "Epoch: 35  accuracy1: 59.177764892578125  accuracy2: 53.99536895751953  accuracy3: 43.65952682495117  overall loss: 0.13458459079265594\n",
      "Epoch: 36  accuracy1: 59.380428314208984  accuracy2: 54.111175537109375  accuracy3: 43.94904708862305  overall loss: 0.13507093489170074\n",
      "Epoch: 37  accuracy1: 59.03300476074219  accuracy2: 54.14012908935547  accuracy3: 43.717430114746094  overall loss: 0.13529708981513977\n",
      "Epoch    38: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 38  accuracy1: 59.090911865234375  accuracy2: 53.821659088134766  accuracy3: 43.60162353515625  overall loss: 0.13571378588676453\n",
      "Epoch: 39  accuracy1: 59.293575286865234  accuracy2: 53.96641540527344  accuracy3: 43.94904708862305  overall loss: 0.1353214532136917\n",
      "Epoch: 40  accuracy1: 59.26462173461914  accuracy2: 54.111175537109375  accuracy3: 43.92009353637695  overall loss: 0.13561499118804932\n",
      "Using device: cuda:0\n",
      "combined2\n",
      "Epoch: 1  accuracy1: 38.30341720581055  accuracy2: 24.811813354492188  accuracy3: 13.839027404785156  overall loss: 0.1632542461156845\n",
      "Epoch: 2  accuracy1: 40.561668395996094  accuracy2: 27.504343032836914  accuracy3: 18.96352195739746  overall loss: 0.15362271666526794\n",
      "Epoch: 3  accuracy1: 45.36769104003906  accuracy2: 35.495079040527344  accuracy3: 26.11465072631836  overall loss: 0.13729533553123474\n",
      "Epoch: 4  accuracy1: 47.394325256347656  accuracy2: 36.132022857666016  accuracy3: 29.50202751159668  overall loss: 0.13304626941680908\n",
      "Epoch: 5  accuracy1: 47.82860565185547  accuracy2: 41.11175537109375  accuracy3: 34.19224166870117  overall loss: 0.12495355308055878\n",
      "Epoch: 6  accuracy1: 48.03126907348633  accuracy2: 42.29878616333008  accuracy3: 35.23451232910156  overall loss: 0.12330622225999832\n",
      "Epoch: 7  accuracy1: 51.56340408325195  accuracy2: 44.0359001159668  accuracy3: 36.68210983276367  overall loss: 0.12000583857297897\n",
      "Epoch: 8  accuracy1: 49.71048355102539  accuracy2: 46.78633499145508  accuracy3: 38.36132049560547  overall loss: 0.1155087873339653\n",
      "Epoch: 9  accuracy1: 51.04227066040039  accuracy2: 48.20498275756836  accuracy3: 38.99826431274414  overall loss: 0.11466530710458755\n",
      "Epoch: 10  accuracy1: 51.21598434448242  accuracy2: 47.973365783691406  accuracy3: 40.33005142211914  overall loss: 0.1128525584936142\n",
      "Epoch: 11  accuracy1: 50.665897369384766  accuracy2: 48.69716262817383  accuracy3: 40.27214813232422  overall loss: 0.11597311496734619\n",
      "Epoch: 12  accuracy1: 51.158077239990234  accuracy2: 47.1916618347168  accuracy3: 40.416908264160156  overall loss: 0.11843100190162659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13  accuracy1: 52.4898681640625  accuracy2: 49.160396575927734  accuracy3: 40.04053497314453  overall loss: 0.12000084668397903\n",
      "Epoch    14: reducing learning rate of group 0 to 1.5000e-03.\n",
      "Epoch: 14  accuracy1: 52.605674743652344  accuracy2: 49.420963287353516  accuracy3: 41.024898529052734  overall loss: 0.1208060085773468\n",
      "Epoch: 15  accuracy1: 55.2982063293457  accuracy2: 53.01100158691406  accuracy3: 44.06485366821289  overall loss: 0.116414375603199\n",
      "Epoch: 16  accuracy1: 54.80602264404297  accuracy2: 51.56340408325195  accuracy3: 43.22524642944336  overall loss: 0.11825385689735413\n",
      "Epoch: 17  accuracy1: 54.86392593383789  accuracy2: 52.8372917175293  accuracy3: 43.60162353515625  overall loss: 0.12142407149076462\n",
      "Epoch    18: reducing learning rate of group 0 to 7.5000e-04.\n",
      "Epoch: 18  accuracy1: 55.9640998840332  accuracy2: 52.663578033447266  accuracy3: 43.74638366699219  overall loss: 0.12275813519954681\n",
      "Epoch: 19  accuracy1: 54.05327224731445  accuracy2: 54.226985931396484  accuracy3: 46.03358459472656  overall loss: 0.12288684397935867\n",
      "Epoch: 20  accuracy1: 55.12449645996094  accuracy2: 54.1690788269043  accuracy3: 45.77301788330078  overall loss: 0.12282194197177887\n",
      "Epoch: 21  accuracy1: 55.26925277709961  accuracy2: 54.54545593261719  accuracy3: 46.38100814819336  overall loss: 0.12368867546319962\n",
      "Epoch    22: reducing learning rate of group 0 to 3.7500e-04.\n",
      "Epoch: 22  accuracy1: 55.90619659423828  accuracy2: 54.74811935424805  accuracy3: 47.04690170288086  overall loss: 0.12430240958929062\n",
      "Epoch: 23  accuracy1: 56.28257369995117  accuracy2: 55.58772659301758  accuracy3: 47.74174880981445  overall loss: 0.12378506362438202\n",
      "Epoch: 24  accuracy1: 56.83266067504883  accuracy2: 55.70353317260742  accuracy3: 47.94441223144531  overall loss: 0.12431389093399048\n",
      "Epoch: 25  accuracy1: 56.45628356933594  accuracy2: 55.41401290893555  accuracy3: 47.6548957824707  overall loss: 0.12478276342153549\n",
      "Epoch    26: reducing learning rate of group 0 to 1.8750e-04.\n",
      "Epoch: 26  accuracy1: 56.74580383300781  accuracy2: 55.79039001464844  accuracy3: 47.45222854614258  overall loss: 0.12590716779232025\n",
      "Epoch: 27  accuracy1: 56.74580383300781  accuracy2: 56.137813568115234  accuracy3: 47.596988677978516  overall loss: 0.12520314753055573\n",
      "Epoch: 28  accuracy1: 57.12217712402344  accuracy2: 56.25362014770508  accuracy3: 47.77070236206055  overall loss: 0.12542352080345154\n",
      "Epoch: 29  accuracy1: 56.62999725341797  accuracy2: 56.601043701171875  accuracy3: 47.915462493896484  overall loss: 0.12679319083690643\n",
      "Epoch    30: reducing learning rate of group 0 to 9.3750e-05.\n",
      "Epoch: 30  accuracy1: 56.57209014892578  accuracy2: 56.48523712158203  accuracy3: 47.56803894042969  overall loss: 0.1272565871477127\n",
      "Epoch: 31  accuracy1: 56.803707122802734  accuracy2: 56.36942672729492  accuracy3: 48.23393249511719  overall loss: 0.12650711834430695\n",
      "Epoch: 32  accuracy1: 56.9774169921875  accuracy2: 56.28257369995117  accuracy3: 48.176029205322266  overall loss: 0.12652279436588287\n",
      "Epoch: 33  accuracy1: 56.71685028076172  accuracy2: 56.51418685913086  accuracy3: 48.3207893371582  overall loss: 0.1266629695892334\n",
      "Epoch    34: reducing learning rate of group 0 to 4.6875e-05.\n",
      "Epoch: 34  accuracy1: 56.803707122802734  accuracy2: 56.48523712158203  accuracy3: 48.03126907348633  overall loss: 0.12703880667686462\n",
      "Epoch: 35  accuracy1: 57.266937255859375  accuracy2: 56.28257369995117  accuracy3: 48.08917236328125  overall loss: 0.12696219980716705\n",
      "Epoch: 36  accuracy1: 57.35379409790039  accuracy2: 56.340476989746094  accuracy3: 48.20498275756836  overall loss: 0.1270332783460617\n",
      "Epoch: 37  accuracy1: 57.61436080932617  accuracy2: 56.340476989746094  accuracy3: 47.973365783691406  overall loss: 0.12692028284072876\n",
      "Epoch    38: reducing learning rate of group 0 to 2.3438e-05.\n",
      "Epoch: 38  accuracy1: 57.643314361572266  accuracy2: 56.398380279541016  accuracy3: 48.03126907348633  overall loss: 0.12727120518684387\n",
      "Epoch: 39  accuracy1: 57.15113067626953  accuracy2: 56.51418685913086  accuracy3: 48.06022262573242  overall loss: 0.12716642022132874\n",
      "Epoch: 40  accuracy1: 57.29589080810547  accuracy2: 56.45628356933594  accuracy3: 48.06022262573242  overall loss: 0.1271093338727951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"cnn\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)\n",
    "train(\"hier\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)\n",
    "train(\"combined1\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)\n",
    "train(\"combined2\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 40, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "pose\n",
      "Epoch: 83  accuracy: 29.47307586669922  loss: 0.23532822728157043\n",
      "Epoch: 84  accuracy: 29.47307586669922  loss: 0.23532825708389282\n",
      "Epoch: 85  accuracy: 29.47307586669922  loss: 0.2353283166885376\n",
      "Epoch: 86  accuracy: 29.47307586669922  loss: 0.2353283315896988\n",
      "Epoch: 87  accuracy: 29.47307586669922  loss: 0.2353283166885376\n",
      "Epoch: 88  accuracy: 29.47307586669922  loss: 0.23532846570014954\n",
      "Epoch: 89  accuracy: 29.47307586669922  loss: 0.2353285402059555\n",
      "Epoch: 90  accuracy: 29.47307586669922  loss: 0.23532865941524506\n",
      "Epoch: 91  accuracy: 29.47307586669922  loss: 0.23532871901988983\n",
      "Epoch: 92  accuracy: 29.47307586669922  loss: 0.2353287786245346\n",
      "Epoch: 93  accuracy: 29.47307586669922  loss: 0.23532874882221222\n",
      "Epoch: 94  accuracy: 29.47307586669922  loss: 0.23532871901988983\n",
      "Epoch: 95  accuracy: 29.47307586669922  loss: 0.23532883822917938\n",
      "Epoch: 96  accuracy: 29.47307586669922  loss: 0.23532900214195251\n",
      "Epoch: 97  accuracy: 29.47307586669922  loss: 0.23532897233963013\n",
      "Epoch: 98  accuracy: 29.47307586669922  loss: 0.23532900214195251\n",
      "Epoch: 99  accuracy: 29.47307586669922  loss: 0.23532910645008087\n",
      "Epoch: 100  accuracy: 29.47307586669922  loss: 0.23532912135124207\n",
      "Using device: cuda:0\n",
      "pose\n",
      "Epoch: 1  accuracy: 12.651997566223145  loss: 0.24001459777355194\n",
      "Epoch: 2  accuracy: 16.01042366027832  loss: 0.22702424228191376\n",
      "Epoch: 3  accuracy: 17.400115966796875  loss: 0.21993018686771393\n",
      "Epoch: 4  accuracy: 18.58714485168457  loss: 0.21521979570388794\n",
      "Epoch: 5  accuracy: 19.62941551208496  loss: 0.2116519957780838\n",
      "Epoch: 6  accuracy: 20.526926040649414  loss: 0.20877021551132202\n",
      "Epoch: 7  accuracy: 21.33757972717285  loss: 0.20631460845470428\n",
      "Epoch: 8  accuracy: 22.235090255737305  loss: 0.2039458006620407\n",
      "Epoch: 9  accuracy: 22.814128875732422  loss: 0.20193496346473694\n",
      "Epoch: 10  accuracy: 23.422119140625  loss: 0.2001771181821823\n",
      "Epoch: 11  accuracy: 24.001157760620117  loss: 0.1985037922859192\n",
      "Epoch: 12  accuracy: 24.609149932861328  loss: 0.19697310030460358\n",
      "Epoch: 13  accuracy: 24.46438980102539  loss: 0.19556096196174622\n",
      "Epoch: 14  accuracy: 25.130285263061523  loss: 0.1942344754934311\n",
      "Epoch: 15  accuracy: 25.217140197753906  loss: 0.19293415546417236\n",
      "Epoch: 16  accuracy: 25.535612106323242  loss: 0.19173520803451538\n",
      "Epoch: 17  accuracy: 25.88303565979004  loss: 0.1906961351633072\n",
      "Epoch: 18  accuracy: 26.17255401611328  loss: 0.1898089200258255\n",
      "Epoch: 19  accuracy: 26.896352767944336  loss: 0.18896542489528656\n",
      "Epoch: 20  accuracy: 27.272727966308594  loss: 0.18824318051338196\n",
      "Epoch: 21  accuracy: 27.156919479370117  loss: 0.18758657574653625\n",
      "Epoch: 22  accuracy: 27.272727966308594  loss: 0.1870921105146408\n",
      "Epoch: 23  accuracy: 27.504343032836914  loss: 0.18659448623657227\n",
      "Epoch: 24  accuracy: 27.475391387939453  loss: 0.18592673540115356\n",
      "Epoch: 25  accuracy: 27.880718231201172  loss: 0.18551500141620636\n",
      "Epoch: 26  accuracy: 28.372901916503906  loss: 0.18501785397529602\n",
      "Epoch: 27  accuracy: 28.778228759765625  loss: 0.1845543384552002\n",
      "Epoch: 28  accuracy: 28.749277114868164  loss: 0.18415191769599915\n",
      "Epoch: 29  accuracy: 28.922988891601562  loss: 0.18380840122699738\n",
      "Epoch: 30  accuracy: 29.183555603027344  loss: 0.18353116512298584\n",
      "Epoch: 31  accuracy: 29.32831573486328  loss: 0.18333593010902405\n",
      "Epoch: 32  accuracy: 29.2414608001709  loss: 0.18299391865730286\n",
      "Epoch: 33  accuracy: 29.5599308013916  loss: 0.18275167047977448\n",
      "Epoch: 34  accuracy: 29.617835998535156  loss: 0.18254677951335907\n",
      "Epoch: 35  accuracy: 29.820499420166016  loss: 0.18237417936325073\n",
      "Epoch: 36  accuracy: 29.820499420166016  loss: 0.18234069645404816\n",
      "Epoch: 37  accuracy: 30.052114486694336  loss: 0.1822557896375656\n",
      "Epoch: 38  accuracy: 30.16792106628418  loss: 0.18207722902297974\n",
      "Epoch: 39  accuracy: 30.225826263427734  loss: 0.18213269114494324\n",
      "Epoch: 40  accuracy: 30.341632843017578  loss: 0.182132288813591\n",
      "Epoch: 41  accuracy: 30.57324981689453  loss: 0.18214260041713715\n",
      "Epoch    42: reducing learning rate of group 0 to 5.0000e-05.\n",
      "Epoch: 42  accuracy: 30.80486488342285  loss: 0.18213820457458496\n",
      "Epoch: 43  accuracy: 31.18124008178711  loss: 0.18059034645557404\n",
      "Epoch: 44  accuracy: 31.23914337158203  loss: 0.18062660098075867\n",
      "Epoch: 45  accuracy: 31.557615280151367  loss: 0.18063059449195862\n",
      "Epoch: 46  accuracy: 31.789230346679688  loss: 0.18065884709358215\n",
      "Epoch    47: reducing learning rate of group 0 to 2.5000e-05.\n",
      "Epoch: 47  accuracy: 31.905038833618164  loss: 0.1807088404893875\n",
      "Epoch: 48  accuracy: 32.339317321777344  loss: 0.17864970862865448\n",
      "Epoch: 49  accuracy: 32.25246047973633  loss: 0.1786675751209259\n",
      "Epoch: 50  accuracy: 32.397220611572266  loss: 0.1786876618862152\n",
      "Epoch: 51  accuracy: 32.36827087402344  loss: 0.17872421443462372\n",
      "Epoch    52: reducing learning rate of group 0 to 1.2500e-05.\n",
      "Epoch: 52  accuracy: 32.28141403198242  loss: 0.17875252664089203\n",
      "Epoch: 53  accuracy: 33.03416442871094  loss: 0.17745870351791382\n",
      "Epoch: 54  accuracy: 33.12102127075195  loss: 0.17748039960861206\n",
      "Epoch: 55  accuracy: 33.09206771850586  loss: 0.17750245332717896\n",
      "Epoch: 56  accuracy: 33.178924560546875  loss: 0.1775316298007965\n",
      "Epoch    57: reducing learning rate of group 0 to 6.2500e-06.\n",
      "Epoch: 57  accuracy: 33.14997100830078  loss: 0.17755217850208282\n",
      "Epoch: 58  accuracy: 33.09206771850586  loss: 0.1770998239517212\n",
      "Epoch: 59  accuracy: 32.976261138916016  loss: 0.177114799618721\n",
      "Epoch: 60  accuracy: 33.063114166259766  loss: 0.1771349161863327\n",
      "Epoch: 61  accuracy: 33.09206771850586  loss: 0.17715179920196533\n",
      "Epoch    62: reducing learning rate of group 0 to 3.1250e-06.\n",
      "Epoch: 62  accuracy: 33.14997100830078  loss: 0.17716604471206665\n",
      "Epoch: 63  accuracy: 32.976261138916016  loss: 0.17707709968090057\n",
      "Epoch: 64  accuracy: 32.976261138916016  loss: 0.17708633840084076\n",
      "Epoch: 65  accuracy: 32.94730758666992  loss: 0.17709487676620483\n",
      "Epoch    66: reducing learning rate of group 0 to 1.5625e-06.\n",
      "Epoch: 66  accuracy: 32.918357849121094  loss: 0.17710264027118683\n",
      "Epoch: 67  accuracy: 32.918357849121094  loss: 0.1770828366279602\n",
      "Epoch: 68  accuracy: 32.918357849121094  loss: 0.17708685994148254\n",
      "Epoch: 69  accuracy: 32.889404296875  loss: 0.17709104716777802\n",
      "Epoch    70: reducing learning rate of group 0 to 7.8125e-07.\n",
      "Epoch: 70  accuracy: 32.918357849121094  loss: 0.17709361016750336\n",
      "Epoch: 71  accuracy: 32.889404296875  loss: 0.17708000540733337\n",
      "Epoch: 72  accuracy: 32.918357849121094  loss: 0.17708005011081696\n",
      "Epoch: 73  accuracy: 32.918357849121094  loss: 0.17708249390125275\n",
      "Epoch    74: reducing learning rate of group 0 to 3.9063e-07.\n",
      "Epoch: 74  accuracy: 32.976261138916016  loss: 0.1770854890346527\n",
      "Epoch: 75  accuracy: 32.94730758666992  loss: 0.17708046734333038\n",
      "Epoch: 76  accuracy: 33.005210876464844  loss: 0.17707966268062592\n",
      "Epoch: 77  accuracy: 33.005210876464844  loss: 0.17707988619804382\n",
      "Epoch    78: reducing learning rate of group 0 to 1.9531e-07.\n",
      "Epoch: 78  accuracy: 32.976261138916016  loss: 0.1770806610584259\n",
      "Epoch: 79  accuracy: 32.94730758666992  loss: 0.17707954347133636\n",
      "Epoch: 80  accuracy: 32.94730758666992  loss: 0.1770792156457901\n",
      "Epoch: 81  accuracy: 32.94730758666992  loss: 0.17707929015159607\n",
      "Epoch    82: reducing learning rate of group 0 to 9.7656e-08.\n",
      "Epoch: 82  accuracy: 32.94730758666992  loss: 0.17707976698875427\n",
      "Epoch: 83  accuracy: 32.94730758666992  loss: 0.1770794689655304\n",
      "Epoch: 84  accuracy: 32.94730758666992  loss: 0.17707934975624084\n",
      "Epoch: 85  accuracy: 32.94730758666992  loss: 0.17707939445972443\n",
      "Epoch    86: reducing learning rate of group 0 to 4.8828e-08.\n",
      "Epoch: 86  accuracy: 32.94730758666992  loss: 0.17707940936088562\n",
      "Epoch: 87  accuracy: 32.94730758666992  loss: 0.17707933485507965\n",
      "Epoch: 88  accuracy: 32.94730758666992  loss: 0.17707934975624084\n",
      "Epoch: 89  accuracy: 32.94730758666992  loss: 0.17707937955856323\n",
      "Epoch    90: reducing learning rate of group 0 to 2.4414e-08.\n",
      "Epoch: 90  accuracy: 32.94730758666992  loss: 0.1770794838666916\n",
      "Epoch: 91  accuracy: 32.94730758666992  loss: 0.17707940936088562\n",
      "Epoch: 92  accuracy: 32.94730758666992  loss: 0.17707942426204681\n",
      "Epoch: 93  accuracy: 32.94730758666992  loss: 0.177079439163208\n",
      "Epoch    94: reducing learning rate of group 0 to 1.2207e-08.\n",
      "Epoch: 94  accuracy: 32.94730758666992  loss: 0.1770794689655304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95  accuracy: 32.94730758666992  loss: 0.17707940936088562\n",
      "Epoch: 96  accuracy: 32.94730758666992  loss: 0.17707926034927368\n",
      "Epoch: 97  accuracy: 32.94730758666992  loss: 0.17707930505275726\n",
      "Epoch: 98  accuracy: 32.94730758666992  loss: 0.1770792454481125\n",
      "Epoch: 99  accuracy: 32.976261138916016  loss: 0.1770792007446289\n",
      "Epoch: 100  accuracy: 32.976261138916016  loss: 0.1770792156457901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(\"pose\", 0.003, weightedHier = [1/3,1/3,1/3], num_epochs = 100, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True, ckp_path = \"./checkpoints/pose_0.003_0.0400\")\n",
    "train(\"pose\", 0.0001, weightedHier = [1/3,1/3,1/3], num_epochs = 100, batch_size = 16, dropout = 0.0,\n",
    "         reproducibility = True, buildGraphs = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
