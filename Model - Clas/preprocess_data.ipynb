{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import torch\n",
    "from pytorchcv.model_provider import get_model as ptcv_get_model\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from os import makedirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainEvalSet(train,eva, path, shuffle = False, check_with_dummy_data=False):\n",
    "    #load data and labels\n",
    "    if check_with_dummy_data == False:\n",
    "        data = np.loadtxt(path + '/data_train.txt')\n",
    "        labels = np.loadtxt(path + '/labels_train.txt')\n",
    "    else:\n",
    "        data, labels = dummyArray()\n",
    "    \n",
    "    #combine data and labels to slice and shuffle\n",
    "    temp = data.size//len(data)\n",
    "    arrayLen,b = data.shape\n",
    "    dataLabels = np.c_[data.reshape(len(data), -1), labels.reshape(len(labels), -1)]\n",
    "    del labels\n",
    "    del data\n",
    "    \n",
    "    #count label occurence to evenly split each label\n",
    "    numOccurrenceEachLabel = []\n",
    "    label = 0\n",
    "    count = 0\n",
    "    size = 0\n",
    "    for i in range(arrayLen):\n",
    "        if dataLabels[i][-1] == label:\n",
    "            count += 1\n",
    "        else:\n",
    "            numOccurrenceEachLabel.append(count)\n",
    "            size += int(count*train)\n",
    "            count = 1\n",
    "            label += 1\n",
    "    numOccurrenceEachLabel.append(count)\n",
    "    size += int(count*train)\n",
    "\n",
    "    #slice and shuffle the data\n",
    "    dataLabels_train = np.zeros((size,b+3))\n",
    "    dataLabels_eval = np.zeros((arrayLen-size,b+3))\n",
    "    occCount = 0\n",
    "    countSteps1 = 0\n",
    "    countSteps2 = 0\n",
    "    for occ in numOccurrenceEachLabel:\n",
    "        slice_ = dataLabels[occCount:occ+occCount]\n",
    "        if shuffle == True:\n",
    "            np.random.shuffle(slice_)\n",
    "        occCount += occ\n",
    "        step1 = int(occ*train)\n",
    "        step2 = occ-step1\n",
    "        dataLabels_train[countSteps1:countSteps1+step1] = slice_[:step1]\n",
    "        dataLabels_eval[countSteps2:countSteps2+step2] = slice_[step1:]\n",
    "        countSteps1 += step1\n",
    "        countSteps2 += step2\n",
    "    del dataLabels\n",
    "    np.random.shuffle(dataLabels_train)\n",
    "    np.random.shuffle(dataLabels_eval)\n",
    "    \n",
    "    #unravel data,labels array\n",
    "    data_train_train = dataLabels_train[:, :temp].reshape(size,b)\n",
    "    labels_train_train = dataLabels_train[:, temp:].reshape(size,3)\n",
    "    data_train_eval = dataLabels_eval[:, :temp].reshape(arrayLen-size,b)\n",
    "    labels_train_eval = dataLabels_eval[:, temp:].reshape(arrayLen-size,3)\n",
    "    \n",
    "    #save data and labels\n",
    "    np.savetxt(path + '/data_train_train.txt', data_train_train, fmt='%d')\n",
    "    np.savetxt(path + '/data_train_eval.txt', data_train_eval, fmt='%d')\n",
    "    np.savetxt(path + '/labels_train_train.txt', labels_train_train)\n",
    "    np.savetxt(path + '/labels_train_eval.txt', labels_train_eval)\n",
    "    if check_with_dummy_data == True:\n",
    "        return data_train_train, data_train_eval, labels_train_train, labels_train_eval\n",
    "    else:\n",
    "        #to Tensor\n",
    "        data_train_train = torch.from_numpy(data_train_train)\n",
    "        labels_train_train = torch.from_numpy(labels_train_train)\n",
    "        data_train_eval = torch.from_numpy(data_train_eval)\n",
    "        labels_train_eval = torch.from_numpy(labels_train_eval)\n",
    "        #save as tensors\n",
    "        torch.save(data_train_train, path + '/data_train_train.pt') \n",
    "        torch.save(data_train_eval, path + '/data_train_eval.pt')\n",
    "        torch.save(labels_train_train, path + '/labels_train_train.pt') \n",
    "        torch.save(labels_train_eval, path + '/labels_train_eval.pt')\n",
    "        return 0\n",
    "    \n",
    "def dummyArray():\n",
    "    data = np.zeros((40,300))\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i] = i\n",
    "    labels = np.zeros((40,3))\n",
    "    setLabels = [5,15,7,13]\n",
    "    count = 0\n",
    "    for i in range(len(setLabels)):\n",
    "        for j in range(setLabels[i]):\n",
    "            labels[count][2] = i\n",
    "            count += 1\n",
    "    return data,labels\n",
    "\n",
    "def addKeypoints(sizeImageInterpolated, path, useTestset = False, saveImages = 0):\n",
    "    #get model for the keypoint prediction\n",
    "    net2 = models.detection.keypointrcnn_resnet50_fpn(pretrained=True, progress=True, num_classes=2, num_keypoints=17, pretrained_backbone=True)\n",
    "    net2.eval()\n",
    "    \n",
    "    #load data\n",
    "    if useTestset == False:\n",
    "        data1 = torch.load(path + '/data_train_train.pt').float()\n",
    "    else:\n",
    "        data1 = torch.load(path + '/data_test.pt').float()\n",
    "        \n",
    "    #predict keypoints\n",
    "    a,b = data1.shape\n",
    "    keyArray = np.zeros((a, 17*3),dtype=float)\n",
    "    print(\"start\")\n",
    "    for i, (datapoint) in enumerate(data1):\n",
    "        if i%30 == 0:\n",
    "            print(\"Train datapoint: \" + str(i) + \"/\" + str(a) + \" processed\")\n",
    "        x = datapoint.view(1,sizeImageInterpolated,sizeImageInterpolated,3)\n",
    "        x = torch.transpose(x, 1, 3)\n",
    "        x = torch.transpose(x, 2, 3)\n",
    "        x /= 255\n",
    "        predictions = net2(x)\n",
    "        keypoints = predictions[0]['keypoints'].detach().numpy()\n",
    "        if keypoints.shape[0] != 0:\n",
    "            keyArray[i] = keypoints[0,:,0:3].flatten()\n",
    "        \n",
    "        #save every 2000 steps\n",
    "        if i%2000 == 0:\n",
    "            if useTestset == False:\n",
    "                np.savetxt(path + '/data_train_train_key.txt', keyArray, fmt='%d')\n",
    "            else:\n",
    "                np.savetxt(path + '/data_test_key.txt', keyArray, fmt='%d')\n",
    "    \n",
    "    #save\n",
    "    if useTestset == False:\n",
    "        np.savetxt(path + '/data_train_train_key.txt', keyArray, fmt='%d')\n",
    "    else:\n",
    "        np.savetxt(path + '/data_test_key.txt', keyArray, fmt='%d')\n",
    "    \n",
    "    #print keypoints into the images\n",
    "    if saveImages != 0:\n",
    "        try:\n",
    "            makedirs('./images_key')\n",
    "        except Exception as e:\n",
    "            None\n",
    "        for i in range(saveImages):\n",
    "            img_key = data1[i].numpy().reshape((sizeImageInterpolated,sizeImageInterpolated,3))\n",
    "            keys = keyArray[i].reshape((17,3))\n",
    "            for k in keys:\n",
    "                j = int(k[0])\n",
    "                l = int(k[1])\n",
    "                img_key[l-1:l+1,j-1:j+1] = [1.,0.,0.]\n",
    "            matplotlib.image.imsave(path + '/images_key/' + str(i) +'.png', img_key)\n",
    "    del data1\n",
    "    del keyArray\n",
    "    \n",
    "    \n",
    "    #also get keypoints for the eval data\n",
    "    if useTestset == False:\n",
    "        data2 = torch.load(path + '/data_train_eval.pt').float()\n",
    "        a,b = data2.shape\n",
    "        keyArray2 = np.zeros((a, 17*3),dtype=float)\n",
    "        for i, (datapoint) in enumerate(data2):\n",
    "            if i%30 == 0:\n",
    "                print(\"Eval datapoint: \" + str(i) + \"/\" + str(a) + \" processed\")\n",
    "            x = datapoint.view(1,sizeImageInterpolated,sizeImageInterpolated,3)\n",
    "            x = torch.transpose(x, 1, 3)\n",
    "            x = torch.transpose(x, 2, 3)\n",
    "            x /= 255\n",
    "            predictions = net2(x)\n",
    "            keypoints = predictions[0]['keypoints'].detach().numpy()\n",
    "            if keypoints.shape[0] != 0:\n",
    "                keyArray2[i] = keypoints[0,:,0:3].flatten()\n",
    "            if i%2000 == 0:\n",
    "                np.savetxt(path + '/data_train_eval_key.txt', keyArray2, fmt='%d')\n",
    "        np.savetxt(path + '/data_train_eval_key.txt', keyArray2, fmt='%d')\n",
    "    return 0\n",
    "\n",
    "def keysToTensor(path, useTestset = False):\n",
    "    if useTestset == False:\n",
    "        keys1 = np.loadtxt(path + '/data_train_train_key.txt')\n",
    "        keys2 = np.loadtxt(path + '/data_train_eval_key.txt')\n",
    "\n",
    "        keysTen1 = torch.from_numpy(keys1)\n",
    "        keysTen2 = torch.from_numpy(keys2)\n",
    "\n",
    "        torch.save(keysTen1, path + '/data_train_train_key.pt') \n",
    "        torch.save(keysTen2, path + '/data_train_eval_key.pt') \n",
    "    else:\n",
    "        keys1 = np.loadtxt(path + '/data_test_key.txt')\n",
    "        keysTen1 = torch.from_numpy(keys1)\n",
    "        torch.save(keysTen1, path + '/data_test_key.pt')\n",
    "    \n",
    "    \n",
    "def getKeypointsInFormOfImages(path, useTestset = False):\n",
    "    #load keypoints\n",
    "    if useTestset == False:\n",
    "        a = torch.load(path + '/data_train_train_key.pt').float()\n",
    "        b = torch.load(path + '/data_train_eval_key.pt').float()\n",
    "        \n",
    "        #generate image-like keypoints from the eval data\n",
    "        eva = torch.zeros(b.shape[0],100,100)\n",
    "        for y,(i) in enumerate(b):\n",
    "            keys = i.view(17,3)\n",
    "            for x,(k) in enumerate(keys):\n",
    "                j = int(k[0])\n",
    "                l = int(k[1])\n",
    "                eva[y,l,j] = 1.0+x*1.0\n",
    "        torch.save(eva, path + '/data_train_eval_key_1.pt')\n",
    "    else:\n",
    "        a = torch.load(path + '/data_test_key.pt').float()\n",
    "        \n",
    "    #generate image-like keypoints from the train or test data \n",
    "    train = torch.zeros(a.shape[0],100,100)\n",
    "    for y,(i) in enumerate(a):\n",
    "        keys = i.view(17,3)\n",
    "        for x,(k) in enumerate(keys):\n",
    "            j = int(k[0])\n",
    "            l = int(k[1])\n",
    "            train[y,l,j] = 1.0+x*1.0\n",
    "    \n",
    "    if useTestset == False:\n",
    "        torch.save(train, path + '/data_train_train_key_1.pt')\n",
    "    else:\n",
    "        torch.save(train, path + '/data_test_key_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split train,eval data\n",
    "splitTrainEvalSet(0.8,0.2, path = './allData', shuffle = True, check_with_dummy_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process train,eval data\n",
    "addKeypoints(100, path = './allData', saveImages = 400)\n",
    "keysToTensor(path = './allData')\n",
    "getKeypointsInFormOfImages(path = './allData', useTestset = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process test data\n",
    "addKeypoints(100, path = './allData', saveImages = 50, useTestset = True)\n",
    "keysToTensor(path = './allData', useTestset = True)\n",
    "getKeypointsInFormOfImages(path = './allData', useTestset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
